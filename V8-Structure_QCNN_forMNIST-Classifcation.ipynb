{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family: 'Computer Modern'; font-size: 36pt; font-weight: bold;\">Quantum Convolutional Neural Network (QCNN) Using *PennyLane*</span>\n",
    "###### <span style=\"font-family: 'Computer Modern'; font-size: 10pt; font-weight: bold;\">Â© 2024 Sean Chisholm</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'Computer Modern'; font-size: 20pt; font-weight: bold;\">Introduction:</span> \n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 15pt;\">This Jupyter Notebook demonstrates the implementation and analysis of a custom Quantum Convolutional Neural Network (QCNN) using PennyLane.</span>\n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 15pt;\">The goal is to apply quantum computing techniques to enhance classical machine learning models for image classification tasks.</span>\n",
    "\n",
    "#### <span style=\"font-family: 'Computer Modern'; font-size: 20pt; font-weight: bold;\">Objective:</span> \n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 15pt;\">The main objective is to create and evaluate a QCNN for classifying the MNIST dataset, showcasing the implementation of quantum convolutional and pooling layers.</span>\n",
    "\n",
    "#### <span style=\"font-family: 'Computer Modern'; font-size: 20pt; font-weight: bold;\">Functionality:</span> \n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 15pt;\">*TODO*</span>\n",
    "\n",
    "#### <span style=\"font-family: 'Computer Modern'; font-size: 20pt; font-weight: bold;\">Dependencies:</span> \n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 15pt;\">This project uses the following libraries:</span>\n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 15pt;\">PennyLane,</span>\n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 15pt;\">NumPy,</span>\n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 15pt;\">Matplotlib,</span>\n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 15pt;\">SciPy</span>\n",
    "\n",
    "#### <span style=\"font-family: 'Computer Modern'; font-size: 20pt; font-weight: bold;\">Structure:</span> \n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 15pt;\">*TODO*</span>\n",
    "\n",
    "#### <span style=\"font-family: 'Computer Modern'; font-size: 20pt; font-weight: bold;\">References and Further Reading:</span> \n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 15pt;\">1. [Source 1 URL]</span>\n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 15pt;\">2. [Source 2 URL]</span>\n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 15pt;\">3. [Source 3 URL]</span>\n",
    "\n",
    "#### <span style=\"font-family: 'Computer Modern'; font-size: 20pt; font-weight: bold;\">Acknowledgements:</span> \n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 15pt;\">This research was conducted under the Laboratory of Particle Physics and Cosmology at Harvard University, led by Professor Carlos Arguelles-Delgado.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Imports_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QML-Based Imports:\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torch\n",
    "\n",
    "# Data Recognition/Visualization Imports:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "# Data Analysis Imports:\n",
    "import random # for generating random data\n",
    "from sklearn import datasets # for data modeling/constructing\n",
    "from sklearn.model_selection import train_test_split # for data modeling/constructing\n",
    "from sklearn.svm import SVC # for data training\n",
    "\n",
    "# PennyLane Demo-Based Imports (MNIST Data):\n",
    "from pennylane.templates import RandomLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TorchVision:\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QML-Drawing-Based Imports:\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# QML Data-Based Imports:\n",
    "from sklearn.preprocessing import OneHotEncoder # for encoding training and testing data labels\n",
    "\n",
    "# NEW Imports:\n",
    "import copy\n",
    "import sys\n",
    "from scipy.linalg import expm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">FUNCTIONS / CLASSES</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gell Mann Matrix Function:\n",
    "\n",
    "def generate_gell_mann(order):\n",
    "    \"\"\"\n",
    "    Generates a list of np.arrays which represent Gell Mann matrices of order 'order'.\n",
    "    eg: order = 2\n",
    "    gm_matrices = [ [[0,  1],\n",
    "                             [1,  0]] ,\n",
    "\n",
    "                            [[0, -i]\n",
    "                             [i,  0]] ,\n",
    "\n",
    "                            [[1,  0],\n",
    "                             [0, -1]] ]\n",
    "    \"\"\"\n",
    "    gm_matrices = []  # Initialize an empty list to store matrices:\n",
    "    for k in range(order):\n",
    "        j = 0\n",
    "        while j < k:\n",
    "            # Generate symmetric and anti-symmetric matrices:\n",
    "            sym = b_mat(j, k, order) + b_mat(k, j, order)  # Create a symmetric matrix:\n",
    "            # Create an anti-symmetric matrix:\n",
    "            anti_sym = complex(0.0, -1.0) * (b_mat(j, k, order) - b_mat(k, j, order))\n",
    "            gm_matrices.append(sym)  # Append symmetric matrix to list:\n",
    "            gm_matrices.append(anti_sym)  # Append anti-symmetric matrix to list:\n",
    "            j += 1\n",
    "\n",
    "        if k < (order - 1):\n",
    "            n = k + 1\n",
    "            coeff = np.sqrt(2 / (n * (n + 1)))  # Calculate coefficient for diagonal matrix:\n",
    "\n",
    "            sum_diag = b_mat(0, 0, order)  # Start with first diagonal element:\n",
    "            for i in range(1, k + 1):\n",
    "                sum_diag += b_mat(i, i, order)  # Sum up to k-th diagonal element:\n",
    "\n",
    "            diag_mat = coeff * (sum_diag - n * (b_mat(k + 1, k + 1, order)))  # Create diagonal matrix:\n",
    "            gm_matrices.append(diag_mat)  # Append diagonal matrix to list:\n",
    "\n",
    "    # Return list of Gell-Mann matrices:\n",
    "    return gm_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Operator Function:\n",
    "\n",
    "def get_conv_op(mats, params):\n",
    "    \"\"\"\n",
    "    Parametrizes the convolutional operator according to Gell-Mann matrices scaled by trainable parameters,\n",
    "    this method generates the relevant applicable operator.\n",
    "    \"\"\"\n",
    "    # Initialize a zero matrix with same shape as Gell-Mann matrices:\n",
    "    final = np.zeros(mats[0].shape, dtype=np.complex128)\n",
    "    for mat, param in zip(mats, params):  # Iterate over pairs of matrices and parameters:\n",
    "        final += param * mat  # Accumulate weighted sum of matrices:\n",
    "\n",
    "    # Return matrix exponential of final matrix:\n",
    "    return expm(complex(0, -1) * final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basis Matrix Function:\n",
    "\n",
    "def b_mat(i, j, n):\n",
    "    \"\"\"\n",
    "    Generates an n x n matrix of 0s with the i,j th entry is a one.\n",
    "    This is the i,j th basis vector on the space of n x n real matricies\n",
    "\n",
    "    :param i: int, row index (must be < n)\n",
    "    :param j: int, column index (must be < n)\n",
    "    :param n: int, dimension of the matrices\n",
    "    :return: np.array of floats, shape (n,n)\n",
    "    \"\"\"\n",
    "    basis_matrix = np.zeros((n, n), dtype=np.float32)\n",
    "    basis_matrix[i, j] = 1.0\n",
    "\n",
    "    return basis_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">DATA</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Loading / Processing_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This function uses TensorFlow to import the MNIST dataset, and due to environment errors, it is currently\n",
    "# not in use. Intead, we import the MNIST dataset using TorchVision.\n",
    "\n",
    "# Using TensorFLow (Currently Not in Use):\n",
    "def load_mnist_tf():\n",
    "    \"\"\"\n",
    "    Load the MNIST dataset and return training and testing images and labels, using TensorFlow.\n",
    "    \n",
    "    Returns:\n",
    "        train_images (numpy.ndarray): Training images.\n",
    "        train_labels (numpy.ndarray): Training labels.\n",
    "        test_images (numpy.ndarray): Testing images.\n",
    "        test_labels (numpy.ndarray): Testing labels.\n",
    "    \"\"\"\n",
    "    # Load MNIST dataset using TensorFlow:\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_images: torch.Size([1000, 1, 28, 28])\n",
      "Shape of train_labels: torch.Size([1000])\n",
      "Shape of test_images: torch.Size([1000, 1, 28, 28])\n",
      "Type of train_images: <class 'torch.Tensor'>\n",
      "Type of train_labels: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Define normalization transform:\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load train data:\n",
    "#-------------------------------------------------------\n",
    "# NOTE: Adjust directory based on your user directory.\n",
    "#-------------------------------------------------------\n",
    "trainset = datasets.MNIST(root='/Users/seanchisholm/NeutrinosSummer24/QML_Summer-2024/QML-JUNE/DATA', train=True,\n",
    "                          transform=transform, download=True)\n",
    "trainloader = DataLoader(trainset, batch_size=1000, shuffle=True)\n",
    "\n",
    "# Download and load test data:\n",
    "#-------------------------------------------------------\n",
    "# NOTE: Adjust directory based on User\n",
    "#-------------------------------------------------------\n",
    "testset = datasets.MNIST(root='/Users/seanchisholm/NeutrinosSummer24/QML_Summer-2024/QML-JUNE/DATA', train=False,\n",
    "                         transform=transform, download=True)\n",
    "testloader = DataLoader(testset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Extract data from loaders:\n",
    "train_images, train_labels = next(iter(trainloader))\n",
    "test_images, test_labels = next(iter(testloader))\n",
    "\n",
    "# Print relevant shapes and types V1:\n",
    "print(\"Shape of train_images:\", train_images.shape)\n",
    "print(\"Shape of train_labels:\", train_labels.shape)\n",
    "print(\"Shape of test_images:\", test_images.shape)\n",
    "print(\"Type of train_images:\", type(train_images))\n",
    "print(\"Type of train_labels:\", type(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Reduction_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_images: torch.Size([103, 1, 28, 28])\n",
      "Shape of train_labels: torch.Size([103])\n",
      "Shape of test_images: torch.Size([22, 1, 28, 28])\n",
      "Shape of test_labels: torch.Size([22])\n",
      "Type of train_images: <class 'torch.Tensor'>\n",
      "Type of train_labels: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Reduce dataset size:\n",
    "n_train = 500\n",
    "n_test = 100\n",
    "train_images = train_images[:n_train]\n",
    "train_labels = train_labels[:n_train]\n",
    "test_images = test_images[:n_test]\n",
    "test_labels = test_labels[:n_test]\n",
    "\n",
    "# Multi-Classification -> Binary Classification:\n",
    "#---------------------------------------------------------------------------\n",
    "# Select indices for classes 0 and 1 in train_labels:\n",
    "train_idx = np.append(np.where(train_labels.numpy() == 0)[0][:n_train//2],\n",
    "                      np.where(train_labels.numpy() == 1)[0][:n_train//2])\n",
    "\n",
    "# Select indices for classes 0 and 1 in test_labels:\n",
    "test_idx = np.append(np.where(test_labels.numpy() == 0)[0][:n_test//2],\n",
    "                     np.where(test_labels.numpy() == 1)[0][:n_test//2])\n",
    "\n",
    "# Convert indices to PyTorch tensors:\n",
    "train_idx = torch.tensor(train_idx, dtype=torch.long)\n",
    "test_idx = torch.tensor(test_idx, dtype=torch.long)\n",
    "\n",
    "# Filter training and testing data based on 'train_idx' and 'test_idx':\n",
    "train_images = train_images[train_idx]\n",
    "test_images = test_images[test_idx]\n",
    "\n",
    "# Filter labels based on based on 'train_idx' and 'test_idx':\n",
    "train_labels = train_labels[train_idx]\n",
    "test_labels = test_labels[test_idx]\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "# Normalize pixel values within [0,1]:\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Print relevant shapes and types V2:\n",
    "print(\"Shape of train_images:\", train_images.shape)\n",
    "print(\"Shape of train_labels:\", train_labels.shape)\n",
    "print(\"Shape of test_images:\", test_images.shape)\n",
    "print(\"Shape of test_labels:\", test_labels.shape)\n",
    "print(\"Type of train_images:\", type(train_images))\n",
    "print(\"Type of train_labels:\", type(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Flattening_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_images: torch.Size([103, 784])\n",
      "Shape of train_labels: torch.Size([103])\n",
      "Shape of test_images: torch.Size([22, 784])\n",
      "Type of train_images: <class 'torch.Tensor'>\n",
      "Type of train_labels: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Flatten images:\n",
    "train_images = train_images.reshape(train_images.shape[0], -1)\n",
    "test_images = test_images.reshape(test_images.shape[0], -1)\n",
    "\n",
    "# Print relevant shapes and types V3:\n",
    "print(\"Shape of train_images:\", train_images.shape)\n",
    "print(\"Shape of train_labels:\", train_labels.shape)\n",
    "print(\"Shape of test_images:\", test_images.shape)\n",
    "print(\"Type of train_images:\", type(train_images))\n",
    "print(\"Type of train_labels:\", type(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">QCNN MODEL</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Optimized Layers_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer Function:\n",
    "def quantum_conv_layer(weights, active_qubits, n_qubits=2):\n",
    "    \"\"\"\n",
    "    Applies a quantum convolutional layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    if np.ndim(weights) == 0:\n",
    "        weights = np.array([weights])\n",
    "    \n",
    "    for i in range(0, n_qubits, 2):\n",
    "        # First rotation on second qubit of pair:\n",
    "        qml.RZ(-np.pi / 2, wires=i + 1)\n",
    "        \n",
    "        # First set of rotations on first qubit of pair:\n",
    "        qml.RZ(weights[0], wires=i)\n",
    "        qml.RY(weights[0], wires=i + 1)\n",
    "        \n",
    "        # First CNOT gate:\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "        \n",
    "        # Second set of rotations on second qubit of pair:\n",
    "        qml.RY(weights[0], wires=i + 1)\n",
    "        \n",
    "        # Second CNOT gate:\n",
    "        qml.CNOT(wires=[i + 1, i])\n",
    "        \n",
    "        # Second rotation on first qubit of pair:\n",
    "        qml.RZ(np.pi / 2, wires=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling Layer Function (V1):\n",
    "def pennylane_pool_layer(weights, n_qubits=2):\n",
    "    \"\"\"\n",
    "    Applies two-qubit pooling operation to inputted qubits, including controlled rotation based on \n",
    "    measurement.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate Gell-Mann matrices for 2-D space (single qubit operators):\n",
    "    pool_operators = generate_gell_mann(2)  # NEW FUNC\n",
    "    \n",
    "    # Loop over all active qubits (in pairs):\n",
    "    for i in range(0, n_qubits, 2):\n",
    "        q1 = i # First qubit\n",
    "        q2 = i + 1 # Second qubit\n",
    "\n",
    "        # Get convolutional operators V1 and V2 from pool operators and weights:\n",
    "        v1 = get_conv_op(pool_operators, weights[0])  # V1 -> First set of weights\n",
    "        v2 = get_conv_op(pool_operators, weights[1])  # V2 -> Second set of weights\n",
    "        \n",
    "        # Apply Hadamard gate to first qubit:\n",
    "        qml.Hadamard(wires=q1)\n",
    "        \n",
    "        # Apply first controlled unitary operation:\n",
    "        qml.ControlledQubitUnitary(v1, control_wires=[q1], wires=[q2])\n",
    "        \n",
    "        # Apply Hadamard gate to second qubit:\n",
    "        qml.Hadamard(wires=q2)\n",
    "        \n",
    "        # Apply second controlled unitary operation:\n",
    "        qml.ControlledQubitUnitary(v2, control_wires=[q2], wires=[q1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED Pooling Layer Function (V2):\n",
    "def pool_layer_mod(weights, active_qubits, n_qubits=2):\n",
    "    \"\"\"\n",
    "    Applies two-qubit pooling operation to inputted qubits, including controlled rotation based on \n",
    "    measurement.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate Gell-Mann matrices for 2-D space (single qubit operators):\n",
    "    pool_operators = generate_gell_mann(2)  # NEW FUNC\n",
    "    \n",
    "    active_qubits = list(range(active_qubits))  # Initialize active qubits\n",
    "\n",
    "    # Loop over all active qubits (in pairs):\n",
    "    for i in range(0, n_qubits, 2):\n",
    "        q1 = active_qubits[i]   # First qubit\n",
    "        q2 = active_qubits[i+1] # Second qubit\n",
    "\n",
    "        # Get convolutional operators V1 and V2 from pool operators and weights:\n",
    "        v1 = get_conv_op(pool_operators, weights[i])  # V1 -> First set of weights\n",
    "        v2 = get_conv_op(pool_operators, weights[i+1])  # V2 -> Second set of weights\n",
    "        \n",
    "        # Apply Hadamard gate to first qubit:\n",
    "        qml.Hadamard(wires=q1)\n",
    "        \n",
    "        # Apply first controlled unitary operation:\n",
    "        qml.ControlledQubitUnitary(v1, control_wires=[q1], wires=[q2])\n",
    "        \n",
    "        # Apply Hadamard gate to second qubit:\n",
    "        qml.Hadamard(wires=q2)\n",
    "        \n",
    "        # Apply second controlled unitary operation:\n",
    "        qml.ControlledQubitUnitary(v2, control_wires=[q2], wires=[q1])\n",
    "        \n",
    "        # Perform PauliZ expectation value measurement on second qubit:\n",
    "        # qml.expval(qml.PauliZ(q2))\n",
    "        qml.measure(q2)\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # return [qml.expval(qml.PauliZ(wire)) for wire in range(0, n_qubits, 2)]\n",
    "    #---------------------------------------------------------------------------\n",
    "    \n",
    "    # Update active qubits by pooling 1 out of every 2 qubits:\n",
    "    active_qubits = active_qubits[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Circuit_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device(s):\n",
    "n_qubits = 2  # Number of qubits\n",
    "active_qubits = 2 # Number of active qubits\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "# QCNN:\n",
    "@qml.qnode(dev, interface='autograd')\n",
    "def q_conv_circuit(params, x, active_qubits, n_qubits=2):\n",
    "    \"\"\"\n",
    "    Defines a quantum circuit for training. This circuit encodes the input features using RX gates, applies\n",
    "    two quantum convolutional layers interleaved with a pooling layer, and measures the expectation value of\n",
    "    Pauli-Z on the first qubit.\n",
    "    \"\"\"\n",
    "    # Apply Amtplitude Embedding:\n",
    "    qml.AmplitudeEmbedding(x, wires=range(n_qubits), normalize=True)\n",
    "    \n",
    "    # Apply first convolutional layer function, pass 'params' as argument:\n",
    "    quantum_conv_layer(params, active_qubits)\n",
    "\n",
    "    # Apply pooling layer, pass 'params' as argument:\n",
    "    pool_layer_mod(params, active_qubits)\n",
    "    \n",
    "    # Return measure of the PauliZ expectation value:\n",
    "    return [qml.expval(qml.PauliZ(wire)) for wire in range(0, n_qubits, 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">TRAINING</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Weights_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_params(params):\n",
    "    \n",
    "    params_complex = params.astype(np.complex128) # Convert to 'complex128'\n",
    "    params = torch.tensor(params_complex) # Convert to TorchVision tensor\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Example Parameter: 0.4907303737641386\n",
      "Shape of 'params': (1024,)\n",
      "Type of 'params': <class 'pennylane.numpy.tensor.tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Transform weights into appropriate broadcasting form:\n",
    "def broadcast_params(params, n_qubits=2):\n",
    "    \n",
    "    # Initialize parameters:\n",
    "    n_qubits = 2  # Number of qubits\n",
    "    \n",
    "    # Flatten images:\n",
    "    params_flat = params.reshape(-1)\n",
    "    # print(params_flat[0])\n",
    "    \n",
    "    opt_length = 2**n_qubits\n",
    "    \n",
    "    # Pad with zeros to match opt_length:\n",
    "    if len(params_flat) < opt_length:\n",
    "        params_flat = np.pad(params_flat, (0, opt_length - len(params_flat)), mode='constant', constant_values=0.0)\n",
    "    \n",
    "    params = np.array(params_flat)\n",
    "    # params = transform_params(params)\n",
    "    \n",
    "    return params\n",
    "\n",
    "# Initialize Parameters:\n",
    "n_qubits = 2\n",
    "active_qubits = 2\n",
    "\n",
    "qcnn_weights = np.random.uniform(0, np.pi, size=(2, n_qubits, 3))\n",
    "# n_layers = 10\n",
    "#qcnn_weights = np.random.uniform(high=np.pi, size=(10,n_qubits))\n",
    "qcnn_weights = broadcast_params(qcnn_weights)\n",
    "\n",
    "# Print relevant shapes and types V5:\n",
    "print(f\"Shape of Example Parameter: {qcnn_weights[0]}\")\n",
    "print(\"Shape of 'params':\", qcnn_weights.shape)\n",
    "print(\"Type of 'params':\", type(qcnn_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Cost_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Multi-Class Labels to Binary Labels (for MSE Function):\n",
    "def bin_class(y, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Converts predicted probabilities to binary classification (0 or 1).\n",
    "    \"\"\"\n",
    "    bin_y = np.where(y >= threshold, 1, 0)\n",
    "    return bin_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error (MSE) Function:\n",
    "def mse_cost(params, x, y, active_qubits, n_qubits=2):\n",
    "    \"\"\"\n",
    "    Computes the Mean Squared Error (MSE) cost function.\n",
    "    \"\"\"\n",
    "    predictions = np.array([q_conv_circuit(params, xi, active_qubits) for xi in x])\n",
    "    return np.mean((bin_class(predictions) - y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Optimization_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (103, 1024), dtype: float32\n",
      "x_test shape: (22, 1024), dtype: float32\n",
      "y_train shape: (103,), dtype: int64\n",
      "y_test shape: (22,), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing Data Instantiation:\n",
    "#----------------------------------------------------------------------------------\n",
    "# x_train = np.array([data[0] for data in train_images])\n",
    "# x_test = np.array([data[0] for data in test_images])\n",
    "x_train = np.array(train_images)\n",
    "x_test = np.array(test_images)\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "# Pad x_train and x_test with zeros to desired shape (,1024):\n",
    "x_train = np.pad(x_train, ((0, 0), (0, 1024 - x_train.shape[1])), mode='constant')\n",
    "x_test = np.pad(x_test, ((0, 0), (0, 1024 - x_test.shape[1])), mode='constant')\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "# Print relevant shapes and types V6:\n",
    "print(f\"x_train shape: {x_train.shape}, dtype: {x_train.dtype}\")\n",
    "print(f\"x_test shape: {x_test.shape}, dtype: {x_test.dtype}\")\n",
    "print(f\"y_train shape: {y_train.shape}, dtype: {y_train.dtype}\")\n",
    "print(f\"y_test shape: {y_test.shape}, dtype: {y_test.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Features must be of length 4; got length 1024. Use the 'pad_with' argument for automated padding.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m loss_history \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[0;32m---> 53\u001b[0m     qcnn_weights, loss \u001b[38;5;241m=\u001b[39m \u001b[43mstoch_grad_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqcnn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mactive_qubits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_qubits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     loss_history\u001b[38;5;241m.\u001b[39mappend(loss)  \u001b[38;5;66;03m# Accumulate loss\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m step_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mstoch_grad_descent\u001b[0;34m(params, x, y, learning_rate, batch_size, active_qubits, n_qubits)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Compute Gradient:\u001b[39;00m\n\u001b[1;32m     33\u001b[0m grad_cost \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mgrad(mse_cost, argnum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m gradients \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactive_qubits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Update Parameters:\u001b[39;00m\n\u001b[1;32m     37\u001b[0m params \u001b[38;5;241m=\u001b[39m params \u001b[38;5;241m-\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m gradients\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pennylane/_grad.py:165\u001b[0m, in \u001b[0;36mgrad.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n\u001b[0;32m--> 165\u001b[0m grad_value, ans \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m ans\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_value\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/autograd/wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pennylane/_grad.py:183\u001b[0m, in \u001b[0;36mgrad._grad_with_forward\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;129m@unary_to_nary\u001b[39m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_grad_with_forward\u001b[39m(fun, x):\n\u001b[1;32m    180\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function is a replica of ``autograd.grad``, with the only\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m    difference being that it returns both the gradient *and* the forward pass\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    value.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     vjp, ans \u001b[38;5;241m=\u001b[39m \u001b[43m_make_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/autograd/core.py:10\u001b[0m, in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_vjp\u001b[39m(fun, x):\n\u001b[1;32m      9\u001b[0m     start_node \u001b[38;5;241m=\u001b[39m VJPNode\u001b[38;5;241m.\u001b[39mnew_root()\n\u001b[0;32m---> 10\u001b[0m     end_value, end_node \u001b[38;5;241m=\u001b[39m  \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m vspace(x)\u001b[38;5;241m.\u001b[39mzeros()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/autograd/tracer.py:10\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace_stack\u001b[38;5;241m.\u001b[39mnew_trace() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[1;32m      9\u001b[0m     start_box \u001b[38;5;241m=\u001b[39m new_box(x, t, start_node)\n\u001b[0;32m---> 10\u001b[0m     end_box \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_box\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isbox(end_box) \u001b[38;5;129;01mand\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_trace \u001b[38;5;241m==\u001b[39m start_box\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_value, end_box\u001b[38;5;241m.\u001b[39m_node\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/autograd/wrap_util.py:15\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f.<locals>.unary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     subargs \u001b[38;5;241m=\u001b[39m subvals(args, \u001b[38;5;28mzip\u001b[39m(argnum, x))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mmse_cost\u001b[0;34m(params, x, y, active_qubits, n_qubits)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmse_cost\u001b[39m(params, x, y, active_qubits, n_qubits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    Computes the Mean Squared Error (MSE) cost function.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([q_conv_circuit(params, xi, active_qubits) \u001b[38;5;28;01mfor\u001b[39;00m xi \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean((bin_class(predictions) \u001b[38;5;241m-\u001b[39m y) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmse_cost\u001b[39m(params, x, y, active_qubits, n_qubits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    Computes the Mean Squared Error (MSE) cost function.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mq_conv_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactive_qubits\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m xi \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean((bin_class(predictions) \u001b[38;5;241m-\u001b[39m y) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pennylane/qnode.py:976\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshots\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_device_shots(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_device)\n\u001b[1;32m    975\u001b[0m \u001b[38;5;66;03m# construct the tape\u001b[39;00m\n\u001b[0;32m--> 976\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    979\u001b[0m using_custom_cache \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__setitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__delitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    983\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pennylane/qnode.py:862\u001b[0m, in \u001b[0;36mQNode.construct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mget_interface(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mqueuing\u001b[38;5;241m.\u001b[39mAnnotatedQueue() \u001b[38;5;28;01mas\u001b[39;00m q:\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qfunc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape \u001b[38;5;241m=\u001b[39m QuantumScript\u001b[38;5;241m.\u001b[39mfrom_queue(q, shots)\n\u001b[1;32m    866\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mq_conv_circuit\u001b[0;34m(params, x, active_qubits, n_qubits)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03mDefines a quantum circuit for training. This circuit encodes the input features using RX gates, applies\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mtwo quantum convolutional layers interleaved with a pooling layer, and measures the expectation value of\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mPauli-Z on the first qubit.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Apply Amtplitude Embedding:\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAmplitudeEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwires\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_qubits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Apply first convolutional layer function, pass 'params' as argument:\u001b[39;00m\n\u001b[1;32m     18\u001b[0m quantum_conv_layer(params, active_qubits)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pennylane/templates/embeddings/amplitude.py:125\u001b[0m, in \u001b[0;36mAmplitudeEmbedding.__init__\u001b[0;34m(self, features, wires, pad_with, normalize, id)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_with \u001b[38;5;241m=\u001b[39m pad_with\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize \u001b[38;5;241m=\u001b[39m normalize\n\u001b[0;32m--> 125\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwires\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_with\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28msuper\u001b[39m(StatePrep, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(features, wires\u001b[38;5;241m=\u001b[39mwires, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pennylane/templates/embeddings/amplitude.py:179\u001b[0m, in \u001b[0;36mAmplitudeEmbedding._preprocess\u001b[0;34m(features, wires, pad_with, normalize)\u001b[0m\n\u001b[1;32m    177\u001b[0m dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(wires)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pad_with \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatures must be of length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; got length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad_with\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument for automated padding.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pad_with \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m>\u001b[39m dim:\n",
      "\u001b[0;31mValueError\u001b[0m: Features must be of length 4; got length 1024. Use the 'pad_with' argument for automated padding."
     ]
    }
   ],
   "source": [
    "# NOTE: Currently Not Operative\n",
    "\n",
    "# Define relevant cost function (Using MSE for now):\n",
    "cost = mse_cost # sets cost func to mean squared error\n",
    "\n",
    "# Parameters for optimization:\n",
    "learning_rate = 0.01\n",
    "num_steps = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize parameters:\n",
    "n_qubits = 2  # Number of qubits\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "# Stochastic Gradient Descent Function:\n",
    "def stoch_grad_descent(params, x, y, learning_rate, batch_size, active_qubits=2, n_qubits=2):\n",
    "    \"\"\"\n",
    "    Updates parameters using stochastic gradient descent and returns the updated parameters and average cost.\n",
    "    \"\"\"\n",
    "    # Shuffle Data:\n",
    "    permutation = np.random.permutation(len(x))\n",
    "    x = x[permutation]\n",
    "    y = y[permutation]\n",
    "\n",
    "    total_cost = 0  # Initialize Total Cost\n",
    "\n",
    "    # Process each Batch:\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        x_batch = x[i:i + batch_size]\n",
    "        y_batch = y[i:i + batch_size]\n",
    "\n",
    "        # Compute Gradient:\n",
    "        grad_cost = qml.grad(mse_cost, argnum=0)\n",
    "        gradients = grad_cost(params, x_batch, y_batch, active_qubits)\n",
    "\n",
    "        # Update Parameters:\n",
    "        params = params - learning_rate * gradients\n",
    "\n",
    "        # Compute Cost for Batch:\n",
    "        batch_cost = mse_cost(params, x_batch, y_batch, active_qubits)\n",
    "        total_cost += batch_cost * len(x_batch)  # Accumulate total cost\n",
    "\n",
    "    # Average Total Cost over all samples\n",
    "    avg_cost = total_cost / len(x)\n",
    "\n",
    "    return params, avg_cost\n",
    "\n",
    "step_size = 5\n",
    "\n",
    "# Training Loop:\n",
    "loss_history = []\n",
    "for step in range(num_steps):\n",
    "    qcnn_weights, loss = stoch_grad_descent(qcnn_weights, x_train, y_train, learning_rate, batch_size,\n",
    "                                            active_qubits=2, n_qubits=2)\n",
    "    loss_history.append(loss)  # Accumulate loss\n",
    "    if step % step_size == 0:\n",
    "        print(f\"Step {step}: cost = {loss}\")\n",
    "\n",
    "# Evaluate optimization on sample test data:\n",
    "predictions = np.array([q_conv_circuit(qcnn_weights, xi, active_qubits) for xi in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Accuracy_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Accuracy:\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred, n_qubits=10):\n",
    "    \n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    total_predictions = len(y_true)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Compute accuracy on test dataset:\n",
    "accuracy = calculate_accuracy(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family: 'Computer Modern'; font-size: 24pt; font-weight: bold;\">APPENDIX: _More Circuits, Gates, Drawings, and Analysis_</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Parameter Characteristics_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing Weights Shape/Size/Behavior:\n",
    "\n",
    "# Define number of qubits:\n",
    "n_qubits = 10\n",
    "\n",
    "# Generate random parameters uniformly distributed between 0 and pi:\n",
    "ex_params = np.random.uniform(0, np.pi, size=(2, n_qubits, 3))\n",
    "print(ex_params)\n",
    "\n",
    "# Parameter shape:\n",
    "print(\"Parameter Shape:\", ex_params.shape)\n",
    "\n",
    "# Parameter length:\n",
    "print(\"Parameter Length:\", len(ex_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Gates_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom General Rotation Gate for (variable) size/shape of weights and wires:\n",
    "def G_Rot(weights, wire):\n",
    "    \"\"\"General Rotation Gate to Qubit.\"\"\"\n",
    "    qml.Rot(weights[0], weights[1], weights[2], wires=wire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Circuits_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With general roations, no 'G_Rot':\n",
    "\n",
    "def two_qubit_pooling(weights):\n",
    "    \n",
    "    # Important parameter values:\n",
    "    n_qubits = 2\n",
    "    n_weights = weights.shape[-1]\n",
    "    \n",
    "    # Apply Rotations/Gates before Measurement:\n",
    "    for i in range(0, n_qubits, 2):\n",
    "        # First set of Rotations (Qubit 1):\n",
    "        qml.Rot(weights[0][i][0], weights[0][i][1], weights[0][i][2], wires=i)\n",
    "        \n",
    "        # First set of Rotations (Qubit 2):\n",
    "        qml.Rot(weights[0][i+1][0], weights[0][i+1][1], weights[0][i+1][2], wires=i+1)\n",
    "    \n",
    "        # First set of CNOT Gates (Qubit 1):\n",
    "        qml.CNOT(wires=[i, i+1])\n",
    "    \n",
    "        # Second set of Rotations (Qubit 1):\n",
    "        qml.Rot(weights[1][i][0], weights[1][i][1], weights[1][i][2], wires=i)\n",
    "    \n",
    "        # Second set of Rotations (Qubit 2):\n",
    "        qml.Rot(weights[1][i+1][0], weights[1][i+1][1], weights[1][i+1][2], wires=i+1)\n",
    "    \n",
    "        # Second set of CNOT Gates (Qubit 2):\n",
    "        qml.CNOT(wires=[i, i+1])\n",
    "    \n",
    "        # Apply controlled rotations (CRot) directly:\n",
    "        qml.CRot(weights[2][i][0], weights[2][i][1], weights[2][i][2], wires=[i, i+1])\n",
    "    \n",
    "    # NOTE: I commented out the PauliZ measure from the pooling function here, but this was strictly to be able to\n",
    "    # use qml.draw below to visualize my results, which requires me to instantiate a circuit uses the layer \n",
    "    # function and returns a measure. When applied to the QCNN as a whole, this needs to be commented back in, or\n",
    "    # else no dimensionality reduction will occur in the QCNN.\n",
    "    \n",
    "    # Perform PauliZ measure to every other Qubit:\n",
    "    #for wire in range(0, n_qubits, 2):\n",
    "    #    qml.expval(qml.PauliZ(wire))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">DRAWINGS</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">Drawing #1: _Original Pooling Layer, \"Every Other Qubit\" Measure (Not Used Currently)_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage #1:\n",
    "\n",
    "n_qubits = 2\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n",
    "\n",
    "# Circuit 1: Every Other Qubit\n",
    "#------------------------------------------------------------------------------\n",
    "@qml.qnode(dev)\n",
    "def circuit1(weights):\n",
    "    two_qubit_pooling(weights)\n",
    "    return [qml.expval(qml.PauliZ(wire)) for wire in range(0, n_qubits, 2)]\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "weights = np.random.random((3, n_qubits, 3))  # Example weights\n",
    "print(f'Pooling Layer Results (2 Qubits) #1:')\n",
    "print(circuit1(weights))\n",
    "\n",
    "# Draw Circuit Layer:\n",
    "unit_drawer1 = qml.draw(circuit1)\n",
    "print(f' -> Pooling Layer with PauliZ Measure @ \"Every Other Qubit\":')\n",
    "print(f'-------------------------------------------------------------------------------')\n",
    "print(unit_drawer1(weights))\n",
    "print(f'-------------------------------------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">Drawing #2: _Original Pooling Layer, \"Second Qubit in Pair\" Measure (Not Used Currently)_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circuit 2: Second Qubit of each Pair\n",
    "@qml.qnode(dev)\n",
    "#------------------------------------------------------------------------------\n",
    "def circuit2(weights):\n",
    "    two_qubit_pooling(weights)\n",
    "    return [qml.expval(qml.PauliZ(wire)) for wire in range(1, n_qubits, 2)]\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "print(f'Pooling Layer Results (2 Qubits) #2:')\n",
    "print(circuit2(weights))\n",
    "\n",
    "# Draw Circuit Layer:\n",
    "unit_drawer2 = qml.draw(circuit2)\n",
    "print(f' -> Pooling Layer with PauliZ Measure @ \"Every Other Qubit\":')\n",
    "print(f'-------------------------------------------------------------------------------')\n",
    "print(unit_drawer2(weights))\n",
    "print(f'-------------------------------------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">Drawing #3: _New Convolutional Layer (Updated Original Layer)_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer function for testing and drawing:\n",
    "\n",
    "def quantum_conv_layer_test(weights):\n",
    "    \"\"\"\n",
    "    Applies a quantum convolutional layer.\n",
    "    \"\"\"\n",
    "    n_qubits = weights.shape[1]  # Number of qubits is second dimension of weights\n",
    "    \n",
    "    for i in range(0, n_qubits, 2):\n",
    "        # First rotation on second qubit of pair:\n",
    "        qml.RZ(-np.pi/2, wires=i + 1)\n",
    "        \n",
    "        # First set of rotations on first qubit of pair:\n",
    "        qml.RZ(weights[0][i][0], wires=i)\n",
    "        qml.RY(weights[0][i][1], wires=i + 1)\n",
    "        \n",
    "        # First CNOT gate:\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "        \n",
    "        # Second set of rotations on second qubit of pair:\n",
    "        qml.RY(weights[0][i][2], wires=i + 1)\n",
    "        \n",
    "        # Second CNOT gate:\n",
    "        qml.CNOT(wires=[i + 1, i])\n",
    "        \n",
    "        # Second rotation on first qubit of pair:\n",
    "        qml.RZ(np.pi/2, wires=i)\n",
    "        \n",
    "# Example usage of the function within QNode:\n",
    "#---------------------------------------------------------------------\n",
    "n_qubits = 2\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n",
    "\n",
    "# Convolutional  Layer Test Drawing:\n",
    "#---------------------------------------------------------------------\n",
    "drawer_beta = qml.draw(quantum_conv_layer_test)\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "weights_b = np.random.random((3, n_qubits, 3))  # Example weights\n",
    "\n",
    "print(f\"Shape of Example Parameter: {weights_b.shape}\")\n",
    "print(\"------------------------\")\n",
    "print(r'Convolutional Layer Circuit (qml.draw):')\n",
    "print(drawer_beta(weights_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">Drawing #4: _New Pooling Layer (Gell-Mann Matrices)_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling Layer function for testing and drawing:\n",
    "\n",
    "def pennylane_pool_layer_test(weights):\n",
    "    \"\"\"\n",
    "    Applies two-qubit pooling operation to inputted qubits, including controlled rotation based on \n",
    "    measurement.\n",
    "    \"\"\"\n",
    "    n_qubits = weights.shape[1]  # Determine number of qubits from weights shape:\n",
    "\n",
    "    # Generate Gell-Mann matrices for 2-D space (single qubit operators):\n",
    "    pool_operators = generate_gell_mann(2)  # NEW FUNC\n",
    "    \n",
    "    # Loop over active qubits in pairs # FOR PAIRS OF QUBITS\n",
    "    for i in range(0, n_qubits, 2):  # FOR PAIRS OF QUBITS\n",
    "        q1 = i        # First qubit:\n",
    "        q2 = i + 1    # Second qubit:\n",
    "\n",
    "        # Extract weights for current qubit pair:\n",
    "        new_weights = weights[:, i, :]  # Shape (a, 3):\n",
    "\n",
    "        # Get convolutional operators V1 and V2 from pool operators and weights:\n",
    "        v1 = get_conv_op(pool_operators, new_weights[0])  # Use first set of weights for V1  # NEW FUNC\n",
    "        v2 = get_conv_op(pool_operators, new_weights[1])  # Use second set of weights for V2  # NEW FUNC\n",
    "\n",
    "        # Apply Hadamard gate to first qubit:\n",
    "        qml.Hadamard(wires=q1)\n",
    "        \n",
    "        # Apply first controlled unitary operation:\n",
    "        qml.ControlledQubitUnitary(v1, control_wires=[q1], wires=[q2])\n",
    "        \n",
    "        # Apply Hadamard gate to second qubit:\n",
    "        qml.Hadamard(wires=q2)\n",
    "        \n",
    "        # Apply second controlled unitary operation:\n",
    "        qml.ControlledQubitUnitary(v2, control_wires=[q2], wires=[q1])\n",
    "\n",
    "# Example usage of the function within QNode:\n",
    "#-------------------------------------------------------------------------\n",
    "n_qubits = 2\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def pool_test_circuit(weights):\n",
    "    pennylane_pool_layer_test(weights)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "weights_a = np.random.random((2, n_qubits, 3))  # Example weights\n",
    "\n",
    "# Pooling Layer Test Drawing:\n",
    "#-------------------------------------------------------------------------\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "n_qubits = 2  # Number of qubits for pooling layer circuit drawing\n",
    "drawer_alpha = qml.draw(pool_test_circuit)\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "print(f\"Shape of Example Parameter: {weights_a.shape}\")\n",
    "print(\"------------------------\")\n",
    "print(r'Pooling Layer Circuit (qml.draw):')\n",
    "print(drawer_alpha(weights_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
