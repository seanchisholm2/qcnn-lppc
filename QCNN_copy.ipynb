{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/d3/13_zdvl17834mj54zgpxzjkr0000gn/T/ipykernel_7854/3643528081.py\", line 6, in <cell line: 6>\n",
      "    import seaborn as sns\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/seaborn/__init__.py\", line 9, in <module>\n",
      "    from .matrix import *  # noqa: F401,F403\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/seaborn/matrix.py\", line 16, in <module>\n",
      "    from . import cm\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/seaborn/cm.py\", line 2, in <module>\n",
      "    from seaborn._compat import register_colormap\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/seaborn/_compat.py\", line 8, in <module>\n",
      "    from seaborn.utils import _version_predates\n",
      "ImportError: cannot import name '_version_predates' from 'seaborn.utils' (/opt/anaconda3/lib/python3.9/site-packages/seaborn/utils.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 1982, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "import jax;\n",
    "\n",
    "# Comment for testing github push/pull\n",
    "\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as jnp\n",
    "import jax.experimental.sparse as jsp\n",
    "import jax.scipy.linalg as jsl \n",
    "\n",
    "import optax  # optimization using jax\n",
    "\n",
    "import pennylane as qml\n",
    "import pennylane.numpy as pnp\n",
    "\n",
    "sns.set()\n",
    "\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "from glob import glob \n",
    "from scipy.linalg import expm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer(weights, wires, skip_first_layer=True):\n",
    "    \"\"\"Adds a convolutional layer to a circuit.\n",
    "    Args:\n",
    "        weights (np.array): 1D array with 15 weights of the parametrized gates.\n",
    "        wires (list[int]): Wires where the convolutional layer acts on.\n",
    "        skip_first_layer (bool): Skips the first two U3 gates of a layer.\n",
    "    \"\"\"\n",
    "    n_wires = len(wires)\n",
    "    assert n_wires >= 3, \"this circuit is too small!\"\n",
    "\n",
    "    for p in [0, 1]:\n",
    "        for indx, w in enumerate(wires):\n",
    "            if indx % 2 == p and indx < n_wires - 1:\n",
    "                if indx % 2 == 0 and not skip_first_layer:\n",
    "                    qml.U3(*weights[:3], wires=[w])\n",
    "                    qml.U3(*weights[3:6], wires=[wires[indx + 1]])\n",
    "                qml.IsingXX(weights[6], wires=[w, wires[indx + 1]])\n",
    "                qml.IsingYY(weights[7], wires=[w, wires[indx + 1]])\n",
    "                qml.IsingZZ(weights[8], wires=[w, wires[indx + 1]])\n",
    "                qml.U3(*weights[9:12], wires=[w])\n",
    "                qml.U3(*weights[12:], wires=[wires[indx + 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have to write all these gates using internal functions specifying Jax! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling_layer(weights, wires):\n",
    "    \"\"\"Adds a pooling layer to a circuit.\n",
    "    Args:\n",
    "        weights (np.array): Array with the weights of the conditional U3 gate.\n",
    "        wires (list[int]): List of wires to apply the pooling layer on.\n",
    "    \"\"\"\n",
    "    n_wires = len(wires)\n",
    "    assert len(wires) >= 2, \"this circuit is too small!\"\n",
    "\n",
    "    for indx, w in enumerate(wires):\n",
    "        if indx % 2 == 1 and indx < n_wires:\n",
    "            m_outcome = qml.measure(w)\n",
    "            #qml.cond applies U3 only if m_outcome == 1 \n",
    "            # if m_outcome == 1:\n",
    "            #     qml.U3(*weights, wires=wires[indx - 1])\n",
    "\n",
    "            qml.cond(m_outcome, qml.U3)(*weights, wires=wires[indx - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_mat(i, j, n):\n",
    "      \n",
    "        basis_matrix = np.zeros((n, n), dtype=np.float32)\n",
    "        basis_matrix[i, j] = 1.0\n",
    "        return basis_matrix\n",
    "        \n",
    "def generate_gell_mann(order):\n",
    "   \n",
    "        gm_matrices = []\n",
    "        for k in range(order):\n",
    "            j = 0\n",
    "            while j < k:\n",
    "                sym = b_mat(j, k, order) + b_mat(k, j, order)\n",
    "                anti_sym = complex(0.0, -1.0) * (b_mat(j, k, order) - b_mat(k, j, order))\n",
    "                gm_matrices.append(sym)\n",
    "                gm_matrices.append(anti_sym)\n",
    "                j += 1\n",
    "\n",
    "            if k < (order - 1):\n",
    "                n = k + 1\n",
    "                coeff = np.sqrt(2 / (n * (n + 1)))\n",
    "                sum_diag = b_mat(0, 0, order)\n",
    "                for i in range(1, k + 1):\n",
    "                    sum_diag += b_mat(i, i, order)\n",
    "                diag_mat = coeff * (sum_diag - n * (b_mat(k + 1, k + 1, order)))\n",
    "                gm_matrices.append(diag_mat)\n",
    "\n",
    "        return gm_matrices\n",
    "\n",
    "def get_conv_op(mats, params):\n",
    "    final = np.zeros(mats[0].shape, dtype=np.complex128)\n",
    "    for mat, param in zip(mats, params):\n",
    "        final += param * mat\n",
    "    return jsl.expm(complex(0, -1) * final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_conv_layer(params, active_qubits, barrier=True):\n",
    "   \n",
    "    conv_operators = generate_gell_mann(4)  # 2 qubit gell mann matricies\n",
    "    u_conv = get_conv_op(conv_operators, params)  \n",
    "\n",
    "    start_index = 0 \n",
    "    index = start_index\n",
    "\n",
    "    while index + 3 < len(active_qubits):\n",
    "        q_index = active_qubits[index]\n",
    "        q_index_1 = active_qubits[index + 1]\n",
    "        q_index_2 = active_qubits[index + 2]\n",
    "        q_index_3 = active_qubits[index + 3]\n",
    "\n",
    "\n",
    "        qml.QubitUnitary(u_conv, [q_index, q_index_1])\n",
    "        qml.QubitUnitary(u_conv, [q_index, q_index_3])\n",
    "        qml.QubitUnitary(u_conv, [q_index, q_index_2])\n",
    "        qml.QubitUnitary(u_conv, [q_index_1, q_index_3])\n",
    "        qml.QubitUnitary(u_conv, [q_index_1, q_index_2])\n",
    "        qml.QubitUnitary(u_conv, [q_index_2, q_index_3])\n",
    "        \n",
    "        qml.Barrier()\n",
    "\n",
    "        if index == 0:\n",
    "            index += 2\n",
    "        else:\n",
    "            index += 3\n",
    "\n",
    "    if barrier:\n",
    "        qml.Barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_conv_layer(params, active_qubits, barrier=True):\n",
    "\n",
    "    conv_operators = generate_gell_mann(8)  # 3 qubit operators\n",
    "    u_conv = get_conv_op(conv_operators, params) #params = 63\n",
    "\n",
    "    start_index = 0 \n",
    "    index = start_index\n",
    "\n",
    "    while index + 2 < len(active_qubits):\n",
    "        q_index = active_qubits[index]\n",
    "        q_index_1 = active_qubits[index + 1]\n",
    "        q_index_2 = active_qubits[index + 2]\n",
    "\n",
    "        qml.QubitUnitary(u_conv, [q_index, q_index_1, q_index_2])\n",
    "        index += 3\n",
    "\n",
    "    if barrier:\n",
    "        qml.Barrier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uniformly_controlled_rotation(params, control_qubit_indicies,\n",
    "                                           target_qubit_index, axis='z'):\n",
    "                                    \n",
    "    num_control_qubits = len(control_qubit_indicies)\n",
    "\n",
    "    divisors = range(num_control_qubits - 1, -1, -1)   # starts from largest divisor to smallest\n",
    "    divisors = [2**i for i in divisors]\n",
    "\n",
    "    for iteration_num, theta in zip(range(1, 2**num_control_qubits + 1), params):\n",
    "        if axis == 'z':\n",
    "            qml.RZ(theta, target_qubit_index)\n",
    "        elif axis == 'y':\n",
    "            qml.RY(theta, target_qubit_index)\n",
    "        else:\n",
    "            qml.RX(theta, target_qubit_index)\n",
    "\n",
    "        for divisor in divisors:\n",
    "            if iteration_num % divisor == 0:\n",
    "                control_element = int((num_control_qubits - 1) - np.log2(divisor))\n",
    "                qml.CNOT(control_qubit_indicies[control_element], target_qubit_index)\n",
    "                break\n",
    "\n",
    "def custom_conv_layer(params, active_qubits, barrier=True):\n",
    "\n",
    "    start_index = 0 \n",
    "    index = start_index\n",
    "    #3 qubit convs \n",
    "    group_size = 2\n",
    "\n",
    "    while index + (group_size - 1) < len(active_qubits):\n",
    "        param_pointer = 0\n",
    "        lst_indicies = range(index, index + group_size)\n",
    "             # z,y ascending loop\n",
    "        for axis in ['z', 'y']:\n",
    "            split_index = group_size - 1\n",
    "            while split_index > 0:\n",
    "                control_indicies = lst_indicies[:split_index]\n",
    "                control_qubit_indicies = [active_qubits[i] for i in control_indicies]\n",
    "                target_qubit_index = active_qubits[lst_indicies[split_index]]\n",
    "\n",
    "                num_local_params = 2**(len(control_qubit_indicies))\n",
    "                local_params = params[param_pointer:param_pointer + num_local_params]\n",
    "                param_pointer += num_local_params\n",
    "\n",
    "                generate_uniformly_controlled_rotation(local_params, control_qubit_indicies,\n",
    "                                                       target_qubit_index, axis=axis)\n",
    "\n",
    "                split_index -= 1\n",
    "\n",
    "            if axis == 'z':\n",
    "                qml.RZ(params[param_pointer], active_qubits[lst_indicies[split_index]])\n",
    "            else:\n",
    "                qml.RY(params[param_pointer], active_qubits[lst_indicies[split_index]])\n",
    "            param_pointer += 1\n",
    "\n",
    "        # descending loop\n",
    "        for axis in ['y', 'z']:\n",
    "            split_index = 1\n",
    "\n",
    "            if axis == 'z':\n",
    "                qml.RZ(params[param_pointer], active_qubits[lst_indicies[split_index-1]])\n",
    "                param_pointer += 1\n",
    "\n",
    "            while split_index < group_size:\n",
    "                control_indicies = lst_indicies[:split_index]\n",
    "                control_qubit_indicies = [active_qubits[i] for i in control_indicies]\n",
    "                target_qubit_index = active_qubits[lst_indicies[split_index]]\n",
    "\n",
    "                num_local_params = 2**(len(control_qubit_indicies))\n",
    "                local_params = params[param_pointer:param_pointer + num_local_params]\n",
    "                param_pointer += num_local_params\n",
    "\n",
    "                generate_uniformly_controlled_rotation(local_params, control_qubit_indicies,\n",
    "                                                       target_qubit_index, axis=axis, label=label)\n",
    "\n",
    "                split_index += 1\n",
    "\n",
    "        index += group_size\n",
    "\n",
    "    if barrier:\n",
    "        qml.Barrier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_copy.ipynb Cell 10\u001b[0m line \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_copy.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     qml\u001b[39m.\u001b[39mQubitUnitary(fc_op, wires\u001b[39m=\u001b[39mwires)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_copy.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m num_wires \u001b[39m=\u001b[39m \u001b[39m6\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_copy.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m device \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mdefault.mixed\u001b[39m\u001b[39m\"\u001b[39m, wires\u001b[39m=\u001b[39mnum_wires)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_copy.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m@qml\u001b[39m\u001b[39m.\u001b[39mqnode(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_copy.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconv_net\u001b[39m(weights, last_layer_weights, features):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_copy.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Define the QCNN circuit\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_copy.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_copy.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m        weights (np.array): Parameters of the convolution and pool layers.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_copy.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m        last_layer_weights (np.array): Parameters of the last dense layer.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_copy.ipynb#X11sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m        features (np.array): Input data to be embedded using AmplitudEmbedding.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qml' is not defined"
     ]
    }
   ],
   "source": [
    "def conv_and_pooling(kernel_weights, n_wires, skip_first_layer=True):\n",
    "    \"\"\"Apply both the convolutional and pooling layer.\"\"\"\n",
    "\n",
    "    if skip_first_layer: \n",
    "        three_conv_layer(kernel_weights[15:78], n_wires, barrier=True)  \n",
    "    else: \n",
    "        four_conv_layer(kernel_weights[:15], n_wires, barrier=True)\n",
    "        three_conv_layer(kernel_weights[15:78], n_wires, barrier=True)\n",
    "    #convolutional_layer(kernel_weights[:15], n_wires, skip_first_layer=skip_first_layer)\n",
    "    pooling_layer(kernel_weights[78:], n_wires)\n",
    "\n",
    "\n",
    "def dense_layer(weights, wires):\n",
    "    \"\"\"Apply an arbitrary unitary gate to a specified set of wires.\"\"\"\n",
    "    # Generate Gell-Mann matrices for vector space:\n",
    "    fc_mats = generate_gell_mann(2**len(wires))\n",
    "    fc_op = get_conv_op(fc_mats, weights)\n",
    "\n",
    "    # Apply Fully Connected Operator to active qubits:\n",
    "    qml.QubitUnitary(fc_op, wires=wires)\n",
    "\n",
    "\n",
    "num_wires = 6\n",
    "device = qml.device(\"default.mixed\", wires=num_wires)\n",
    "\n",
    "\n",
    "@qml.qnode(device)\n",
    "def conv_net(weights, last_layer_weights, features):\n",
    "    \"\"\"Define the QCNN circuit\n",
    "    Args:\n",
    "        weights (np.array): Parameters of the convolution and pool layers.\n",
    "        last_layer_weights (np.array): Parameters of the last dense layer.\n",
    "        features (np.array): Input data to be embedded using AmplitudEmbedding.\"\"\"\n",
    "\n",
    "    layers = weights.shape[1]\n",
    "    wires = list(range(num_wires))\n",
    "\n",
    "    # inputs the state input_state\n",
    "    qml.QubitDensityMatrix(features, wires=wires)\n",
    "    #qml.AmplitudeEmbedding(features=features, wires=wires, pad_with=0.5)\n",
    "    qml.Barrier(wires=wires, only_visual=True)\n",
    "\n",
    "\n",
    "    # adds convolutional and pooling layers\n",
    "    for j in range(layers):\n",
    "        conv_and_pooling(weights[:, j], wires, skip_first_layer=(not j == 0))\n",
    "        wires = wires[::2]\n",
    "        qml.Barrier(wires=wires, only_visual=True)\n",
    "\n",
    "    assert last_layer_weights.size == 4 ** (len(wires)) - 1, (\n",
    "        \"The size of the last layer weights vector is incorrect!\"\n",
    "        f\" \\n Expected {4 ** (len(wires)) - 1}, Given {last_layer_weights.size}\"\n",
    "    )\n",
    "    dense_layer(last_layer_weights, wires)\n",
    "    return qml.probs(wires=(0))\n",
    "\n",
    "\n",
    "fig, ax = qml.draw_mpl(conv_net)(\n",
    "    np.random.rand(81, 2), np.random.rand(4 ** 2 - 1), np.random.rand(2 ** num_wires)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "images, labels = digits.data, digits.target\n",
    "\n",
    "images = images[np.where((labels == 0) | (labels == 1))]\n",
    "#images = np.pad(images, (0, 2**num_wires - len(images[0])), constant_values=0)\n",
    "labels = labels[np.where((labels == 0) | (labels == 1))]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=12, figsize=(3, 1))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(images[i].reshape((8,8)), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_digits_data(num_train, num_test, rng):\n",
    "    \"\"\"Return training and testing data of digits dataset.\"\"\"\n",
    "    digits = datasets.load_digits()\n",
    "    features, labels = digits.data, digits.target\n",
    "\n",
    "    # only use first two classes\n",
    "    features = features[np.where((labels == 0) | (labels == 1))]\n",
    "    labels = labels[np.where((labels == 0) | (labels == 1))]\n",
    "\n",
    "    # normalize data\n",
    "    features = features / np.linalg.norm(features, axis=1).reshape((-1, 1))\n",
    "\n",
    "    # subsample train and test split\n",
    "    train_indices = rng.choice(len(labels), num_train, replace=False)\n",
    "    test_indices = rng.choice(\n",
    "        np.setdiff1d(range(len(labels)), train_indices), num_test, replace=False\n",
    "    )\n",
    "\n",
    "    x_train, y_train = features[train_indices], labels[train_indices]\n",
    "    x_test, y_test = features[test_indices], labels[test_indices]\n",
    "\n",
    "    return (\n",
    "        jnp.asarray(x_train),\n",
    "        jnp.asarray(y_train),\n",
    "        jnp.asarray(x_test),\n",
    "        jnp.asarray(y_test),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_IC_data(num_train, num_test, rng):\n",
    "\n",
    "    cascade_files = glob(\"/Users/pavelzhelnin/Downloads/1024_length/cascades/*.npy\") # CHANGE USER\n",
    "    track_files = glob(\"/Users/pavelzhelnin/Downloads/1024_length/tracks/*.npy\") # CHANGE USER\n",
    "\n",
    "    # # subsample train and test split\n",
    "\n",
    "    cascade_sub_indices = rng.choice(len(track_files), len(track_files), replace = False)\n",
    "    cascade_sub = np.array(cascade_files)[cascade_sub_indices]\n",
    "    tracks_cascades = np.concatenate((cascade_sub,np.array(track_files)),axis=0)\n",
    "    labels = np.concatenate((np.zeros(len(cascade_sub)),np.ones(len(track_files))),axis=0)\n",
    "\n",
    "    len_labels = len(cascade_sub) + len(track_files)\n",
    "\n",
    "    train_indices = rng.choice(len_labels, num_train, replace=False)\n",
    "    test_indices = rng.choice(\n",
    "        np.setdiff1d(range(len_labels), train_indices), num_test, replace=False\n",
    "    )\n",
    "\n",
    "    test_labels = labels[test_indices]\n",
    "    train_labels = labels[train_indices]\n",
    "\n",
    "    test_data = jsp.BCOO.fromdense(jnp.array([np.load(tracks_cascades[i], allow_pickle=True).tolist().todense() for i in test_indices]),n_batch=2)\n",
    "    train_data = jsp.BCOO.fromdense(jnp.array([np.load(tracks_cascades[i], allow_pickle=True).tolist().todense() for i in train_indices]),n_batch=2)\n",
    "        \n",
    "    x_train = train_data\n",
    "    y_train = train_labels\n",
    "    x_test = test_data\n",
    "    y_test = test_labels\n",
    "\n",
    "    print(test_data.shape)\n",
    "    return (\n",
    "       x_train,jnp.asarray(y_train),x_test,jnp.asarray(y_test)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_out(weights,weights_last,features,labels): \n",
    "#     cost = [conv_net(weights, weights_last, feature) for feature in features] \n",
    "#     return cost \n",
    "\n",
    "# def compute_accuracy(weights,weights_last,features,labels):\n",
    "#     out = compute_out(weights,weights_last,features,labels)\n",
    "#     return np.sum(out > 0.5) / len(out)\n",
    "\n",
    "# def compute_cost(weights, weights_last, features, labels):\n",
    "#     \"\"\"Computes the cost over the provided features and labels\"\"\"\n",
    "#     out = compute_out(weights, weights_last, features, labels)\n",
    "#     return 1.0 - np.sum(out) / len(labels)\n",
    "\n",
    "\n",
    "# def init_weights():\n",
    "#     \"\"\"Initializes random weights for the QCNN model.\"\"\"\n",
    "#     weights = np.random.normal(loc=0, scale=1, size=(18, 2), requires_grad=True)\n",
    "#     weights_last = np.random.normal(loc=0, scale=1, size=4 ** 2 - 1, requires_grad=True)\n",
    "#     return np.array(weights), np.array(weights_last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_moments(num_train, num_test, rng): \n",
    "    cascade_files = glob(\"/Users/pavelzhelnin/Documents/physics/qcml/vqc/cascade_moments/*.npy\")\n",
    "    track_files = glob(\"/Users/pavelzhelnin/Documents/physics/qcml/vqc/track_moments/*.npy\")\n",
    "    x_track_train = []\n",
    "    y_track_train = []\n",
    "    for f in track_files:\n",
    "        data = jnp.load(f, allow_pickle=True)\n",
    "        x_track_train.append(data/jnp.linalg.norm(data))\n",
    "        y_track_train.append(1)\n",
    "\n",
    "    x_cascade_train = []  \n",
    "    y_cascade_train = []\n",
    "    for f in cascade_files:\n",
    "        data = jnp.load(f, allow_pickle=True)\n",
    "        x_cascade_train.append(data/jnp.linalg.norm(data))\n",
    "        y_cascade_train.append(0)\n",
    "\n",
    "    features = x_track_train + x_cascade_train\n",
    "    labels = y_track_train + y_cascade_train\n",
    "\n",
    "    # subsample train and test split\n",
    "    train_indices = rng.choice(len(labels), num_train, replace=False)\n",
    "    test_indices = rng.choice(\n",
    "        np.setdiff1d(range(len(labels)), train_indices), num_test, replace=False\n",
    "    )\n",
    "\n",
    "    x_train = np.array([features[i] for i in train_indices])\n",
    "    y_train = np.array([labels[i] for i in train_indices])\n",
    "    x_test = np.array([features[i] for i in test_indices])\n",
    "    y_test = np.array([labels[i] for i in test_indices])\n",
    "\n",
    "    return (\n",
    "        jnp.asarray(x_train),\n",
    "        jnp.asarray(y_train),\n",
    "        jnp.asarray(x_test),\n",
    "        jnp.asarray(y_test),\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_out(weights, weights_last, features, labels):\n",
    "    \"\"\"Computes the output of the corresponding label in the qcnn\"\"\"\n",
    "    cost = lambda weights, weights_last, feature, label: conv_net(weights, weights_last, feature)[\n",
    "        label\n",
    "    ]\n",
    "    return jax.vmap(cost, in_axes=(None, None, 0, 0), out_axes=0)(\n",
    "        weights, weights_last, features, labels\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_accuracy(weights, weights_last, features, labels):\n",
    "    \"\"\"Computes the accuracy over the provided features and labels\"\"\"\n",
    " \n",
    "    out = compute_out(weights, weights_last, features, labels)\n",
    "    return jnp.sum(out > 0.5) / len(out)\n",
    "\n",
    "\n",
    "def compute_cost(weights, weights_last, features, labels):\n",
    "    \"\"\"Computes the cost over the provided features and labels\"\"\"\n",
    "    out = compute_out(weights, weights_last, features, labels)\n",
    "    return 1.0 - jnp.sum(out) / len(labels)\n",
    "\n",
    "\n",
    "def init_weights():\n",
    "    \"\"\"Initializes random weights for the QCNN model.\"\"\"\n",
    "    weights = pnp.random.normal(loc=0, scale=1, size=(81, 2), requires_grad=True)\n",
    "    weights_last = pnp.random.normal(loc=0, scale=1, size=4 ** 3 - 1, requires_grad=True)\n",
    "    return jnp.array(weights), jnp.array(weights_last)\n",
    "\n",
    "\n",
    "value_and_grad = jax.jit(jax.value_and_grad(compute_cost, argnums=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_qcnn(n_train, n_test, n_epochs):\n",
    "    \n",
    "    #x_train, y_train, x_test, y_test = load_digits_data(n_train, n_test, rng)\n",
    "    #x_train, y_train, x_test, y_test = load_moments(n_train, n_test, rng)\n",
    "    x_train, y_train, x_test, y_test = load_IC_data(n_train, n_test, rng)\n",
    "\n",
    "\n",
    "    weights, weights_last = init_weights()\n",
    "\n",
    "    cosine_decay_scheduler = optax.cosine_decay_schedule(0.1, decay_steps=n_epochs, alpha=0.95)\n",
    "    optimizer = optax.adam(learning_rate=cosine_decay_scheduler)\n",
    "    opt_state = optimizer.init((weights, weights_last))\n",
    "\n",
    "    train_cost_epochs, test_cost_epochs, train_acc_epochs, test_acc_epochs = [], [], [], []\n",
    "\n",
    "    for step in range(n_epochs):\n",
    "        train_cost, grad_circuit = value_and_grad(weights, weights_last, x_train, y_train)\n",
    "        updates, opt_state = optimizer.update(grad_circuit, opt_state)\n",
    "        weights, weights_last = optax.apply_updates((weights, weights_last), updates)\n",
    "\n",
    "        train_cost_epochs.append(train_cost)\n",
    "\n",
    "        train_acc = compute_accuracy(weights, weights_last, x_train, y_train)\n",
    "        train_acc_epochs.append(train_acc)\n",
    "\n",
    "        test_out = compute_out(weights, weights_last, x_test, y_test)\n",
    "        test_acc = jnp.sum(test_out > 0.5) / len(test_out)\n",
    "        test_acc_epochs.append(test_acc)\n",
    "        test_cost = 1.0 - jnp.sum(test_out) / len(test_out)\n",
    "        test_cost_epochs.append(test_cost)\n",
    "\n",
    "    return dict(\n",
    "        n_train=[n_train] * n_epochs,\n",
    "        step=np.arange(1, n_epochs + 1, dtype=int),\n",
    "        train_cost=train_cost_epochs,\n",
    "        train_acc=train_acc_epochs,\n",
    "        test_cost=test_cost_epochs,\n",
    "        test_acc=test_acc_epochs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 2\n",
    "n_epochs = 100\n",
    "n_reps = 10\n",
    "\n",
    "def run_iterations(n_train):\n",
    "    results_df = pd.DataFrame(\n",
    "        columns=[\"train_acc\", \"train_cost\", \"test_acc\", \"test_cost\", \"step\", \"n_train\"]\n",
    "    )\n",
    "\n",
    "    for _ in range(n_reps):\n",
    "        results = train_qcnn(n_train=n_train, n_test=n_test, n_epochs=n_epochs)\n",
    "        results_df = pd.concat(\n",
    "            [results_df, pd.DataFrame.from_dict(results)], axis=0, ignore_index=True\n",
    "        )\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# run training for multiple sizes\n",
    "#train_sizes = [2, 5, 10, 20, 40, 80]\n",
    "train_sizes = [2]\n",
    "results_df = run_iterations(n_train=2)\n",
    "for n_train in train_sizes[1:]:\n",
    "    results_df = pd.concat([results_df, run_iterations(n_train=n_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate dataframe\n",
    "df_agg = results_df.groupby([\"n_train\", \"step\"]).agg([\"mean\", \"std\"])\n",
    "df_agg = df_agg.reset_index()\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "colors = sns.color_palette()\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(16.5, 5))\n",
    "\n",
    "generalization_errors = []\n",
    "train_sizes = [2, 5, 10]\n",
    "# plot losses and accuracies\n",
    "for i, n_train in enumerate(train_sizes):\n",
    "    df = df_agg[df_agg.n_train == n_train]\n",
    "\n",
    "    dfs = [df.train_cost[\"mean\"], df.test_cost[\"mean\"], df.train_acc[\"mean\"], df.test_acc[\"mean\"]]\n",
    "    lines = [\"o-\", \"x--\", \"o-\", \"x--\"]\n",
    "    labels = [fr\"$N={n_train}$\", None, fr\"$N={n_train}$\", None]\n",
    "    axs = [0,0,1,1]\n",
    "\n",
    "    for k in range(4):\n",
    "        ax = axes[axs[k]]\n",
    "        ax.plot(df.step, dfs[k], lines[k], label=labels[k], markevery=10, color=colors[i], alpha=0.8)\n",
    "\n",
    "\n",
    "    # plot final loss difference\n",
    "    dif = df[df.step == 100].test_cost[\"mean\"] - df[df.step == 100].train_cost[\"mean\"]\n",
    "    generalization_errors.append(dif)\n",
    "\n",
    "# format loss plot\n",
    "ax = axes[0]\n",
    "ax.set_title('Train and Test Losses', fontsize=14)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "\n",
    "# format generalization error plot\n",
    "# ax = axes[1]\n",
    "# ax.plot(train_sizes, generalization_errors, \"o-\", label=r\"$gen(\\alpha)$\")\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_xticks(train_sizes)\n",
    "# ax.set_xticklabels(train_sizes)\n",
    "# ax.set_title(r'Generalization Error $gen(\\alpha) = R(\\alpha) - \\hat{R}_N(\\alpha)$', fontsize=14)\n",
    "# ax.set_xlabel('Training Set Size')\n",
    "\n",
    "# format loss plot\n",
    "ax = axes[1]\n",
    "ax.set_title('Train and Test Accuracies', fontsize=14)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_ylim(0.5, 1.05)\n",
    "\n",
    "legend_elements = [\n",
    "    mpl.lines.Line2D([0], [0], label=f'N={n}', color=colors[i]) for i, n in enumerate(train_sizes)\n",
    "    ] + [\n",
    "    mpl.lines.Line2D([0], [0], marker='o', ls='-', label='Train', color='Black'),\n",
    "    mpl.lines.Line2D([0], [0], marker='x', ls='--', label='Test', color='Black')\n",
    "    ]\n",
    "\n",
    "axes[0].legend(handles=legend_elements, ncol=3)\n",
    "axes[1].legend(handles=legend_elements, ncol=3)\n",
    "\n",
    "#axes[1].set_yscale('log', base=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_out(weights, weights_last, features, labels):\n",
    "    \"\"\"Computes the output of the corresponding label in the qcnn\"\"\"\n",
    "    cost = lambda weights, weights_last, feature, label: conv_net(weights, weights_last, feature)[\n",
    "        label\n",
    "    ]\n",
    "    return jax.vmap(cost, in_axes=(None, None, 0, 0), out_axes=0)(\n",
    "        weights, weights_last, features, labels\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_accuracy(weights, weights_last, features, labels):\n",
    "    \"\"\"Computes the accuracy over the provided features and labels\"\"\"\n",
    " \n",
    "    out = compute_out(weights, weights_last, features, labels)\n",
    "    return jnp.sum(out > 0.5) / len(out)\n",
    "\n",
    "\n",
    "def compute_cost(weights, weights_last, features, labels):\n",
    "    \"\"\"Computes the cost over the provided features and labels\"\"\"\n",
    "    out = compute_out(weights, weights_last, features, labels)\n",
    "    return 1.0 - jnp.sum(out) / len(labels)\n",
    "\n",
    "\n",
    "def init_weights():\n",
    "    \"\"\"Initializes random weights for the QCNN model.\"\"\"\n",
    "    weights = pnp.random.normal(loc=0, scale=1, size=(81, 1), requires_grad=True)\n",
    "    weights_last = pnp.random.normal(loc=0, scale=1, size=4 ** 3 - 1, requires_grad=True)\n",
    "    return jnp.array(weights), jnp.array(weights_last)\n",
    "\n",
    "\n",
    "value_and_grad = jax.jit(jax.value_and_grad(compute_cost, argnums=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train=2\n",
    "num_test=2\n",
    "cascade_files = glob(\"/Users/pavelzhelnin/Documents/physics/qcml/vqc/spacetime_cascades/*.npz\")\n",
    "track_files = glob(\"/Users/pavelzhelnin/Documents/physics/qcml/vqc/spacetime_tracks/*.npz\")\n",
    "x_track_train = []\n",
    "y_track_train = []\n",
    "for f in track_files:\n",
    "    data = np.load(f, allow_pickle=True)['arr_0'] \n",
    "    if data.tolist().shape[0] == 1024:\n",
    "        x_track_train.append(data.tolist())\n",
    "        y_track_train.append(1)\n",
    "\n",
    "x_cascade_train = []  \n",
    "y_cascade_train = []\n",
    "for f in cascade_files:\n",
    "    data = np.load(f, allow_pickle=True)['arr_0']\n",
    "    if data.tolist().shape[0] == 1024:\n",
    "        x_cascade_train.append(data.tolist())\n",
    "        y_cascade_train.append(0)\n",
    "    \n",
    "features = x_track_train + x_cascade_train\n",
    "labels = y_track_train + y_cascade_train\n",
    "\n",
    "\n",
    "# subsample train and test split\n",
    "train_indices = rng.choice(len(labels), num_train, replace=False)\n",
    "test_indices = rng.choice(\n",
    "    np.setdiff1d(range(len(labels)), train_indices), num_test, replace=False\n",
    ")\n",
    "\n",
    "x_train = [jsp.BCSR.from_scipy_sparse(features[i]) for i in train_indices]\n",
    "y_train = np.array([labels[i] for i in train_indices])\n",
    "x_test = [jsp.BCSR.from_scipy_sparse(features[i]) for i in test_indices]\n",
    "y_test = np.array([labels[i] for i in test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.n_batch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = jsp.BCSR(a, n_batch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hstack(features[train_indices[0]],features[train_indices[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsp.BCOO.fromdense(jnp.array([features[train_indices[0]].todense(),features[train_indices[1]].todense()])).indices.ndim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsp.bcoo_concatenate(jnp.asarray(jsp.BCSR.from_scipy_sparse(features[train_indices[0]]).to_bcoo(),jsp.BCSR.from_scipy_sparse(features[train_indices[1]]).to_bcoo()),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_array = jnp.array(\n",
    "        [\n",
    "            [\n",
    "                [0,0,0],\n",
    "                [2,2,2],\n",
    "                [0,0,0],\n",
    "                [0,0,0]\n",
    "            ],\n",
    "            [\n",
    "                [1,1,1],\n",
    "                [0,0,0],\n",
    "                [0,0,0],\n",
    "                [0,0,0]\n",
    "            ],\n",
    "            [\n",
    "                [1,1,1],\n",
    "                [0,0,0],\n",
    "                [0,0,0],\n",
    "                [0,0,0]\n",
    "            ]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_array = jsp.bcoo_fromdense(full_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_array.indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_files = glob(\"/Users/pavelzhelnin/Documents/physics/qcml/vqc/spacetime_cascades/*.npz\")\n",
    "track_files = glob(\"/Users/pavelzhelnin/Documents/physics/qcml/vqc/spacetime_tracks/*.npz\")\n",
    "x_track_train = []\n",
    "y_track_train = []\n",
    "for f in track_files:\n",
    "    data = np.load(f, allow_pickle=True)['arr_0'] \n",
    "    if data.tolist().shape[0] == 1024:\n",
    "        filename = \"1024_length/tracks/\" + f.split(\"/\")[-1].split(\".\")[0] + \".npy\"\n",
    "        np.save(filename,data)\n",
    "        y_track_train.append(1)\n",
    "\n",
    "x_cascade_train = []  \n",
    "y_cascade_train = []\n",
    "for f in cascade_files:\n",
    "    data = np.load(f, allow_pickle=True)['arr_0']\n",
    "    if data.tolist().shape[0] == 1024:\n",
    "        filename = \"1024_length/cascades/\" + f.split(\"/\")[-1].split(\".\")[0] + \".npy\"\n",
    "        np.save(filename,data)\n",
    "        y_cascade_train.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_track_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time() \n",
    "cascade_files = glob(\"/Users/pavelzhelnin/Downloads/1024_length/cascades/*.npy\")\n",
    "track_files = glob(\"/Users/pavelzhelnin/Downloads/1024_length/tracks/*.npy\")\n",
    "\n",
    "num_train = 2 \n",
    "num_test = 2\n",
    "# # subsample train and test split\n",
    "\n",
    "cascade_sub_indices = rng.choice(len(track_files), len(track_files), replace = False)\n",
    "cascade_sub = np.array(cascade_files)[cascade_sub_indices]\n",
    "tracks_cascades = np.concatenate((cascade_sub,np.array(track_files)),axis=0)\n",
    "labels = np.concatenate((np.zeros(len(cascade_sub)),np.ones(len(track_files))),axis=0)\n",
    "\n",
    "len_labels = len(cascade_sub) + len(track_files)\n",
    "\n",
    "train_indices = rng.choice(len_labels, num_train, replace=False)\n",
    "test_indices = rng.choice(\n",
    "    np.setdiff1d(range(len_labels), train_indices), num_test, replace=False\n",
    ")\n",
    "\n",
    "test_labels = labels[test_indices]\n",
    "train_labels = labels[train_indices]\n",
    "\n",
    "test_data = jsp.BCOO.fromdense(jnp.array([np.load(tracks_cascades[i], allow_pickle=True).tolist().todense() for i in test_indices]),n_batch=1)\n",
    "train_data = jsp.BCOO.fromdense(jnp.array([np.load(tracks_cascades[i], allow_pickle=True).tolist().todense() for i in train_indices]),n_batch=1)\n",
    "\n",
    "print(time.time()-start) \n",
    "# features = x_track_train + x_cascade_train\n",
    "# labels = y_track_train + y_cascade_train\n",
    "\n",
    "\n",
    "# x_train = [jsp.BCSR.from_scipy_sparse(features[i]) for i in train_indices]\n",
    "# y_train = np.array([labels[i] for i in train_indices])\n",
    "# x_test = [jsp.BCSR.from_scipy_sparse(features[i]) for i in test_indices]\n",
    "# y_test = np.array([labels[i] for i in test_indices])\n",
    "\n",
    "\n",
    "# x_train,jnp.asarray(y_train),x_test,jnp.asarray(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(tracks_cascades[i], allow_pickle=True).tolist()\n",
    "b = np.load(tracks_cascades[2], allow_pickle=True).tolist()\n",
    "print(a.tocoo().row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = a.tocoo().row\n",
    "col = a.tocoo().col \n",
    "data = a.tocoo().data \n",
    "\n",
    "row_b = b.tocoo().row\n",
    "col_b = b.tocoo().col\n",
    "data_b = b.tocoo().data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.array([data_b,data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsp.BCOO((jnp.array([data),np.column_stack((row,col))),shape=(1024,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsp.BCOO((jnp.array([1.]),jnp.array([[0,0]])),shape=(1024,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.vstack((row,col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
