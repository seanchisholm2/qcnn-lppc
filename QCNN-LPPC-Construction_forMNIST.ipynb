{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family: 'Computer Modern'; font-size: 42pt; font-weight: bold;\">Quantum Convolutional Neural Network (QCNN) Using *PennyLane*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS / DEPENDENCIES:\n",
    "\n",
    "# PennyLane:\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches # Quantum Circuit Drawings\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "\n",
    "from scipy.linalg import expm # Unitary-Related Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PACKAGE IMPORTS (UN-COMMENT WHEN COMPLETED)\n",
    "\n",
    "## gellmann_ops.py\n",
    "#from gellmann_ops import GellMannOps as gell # GELL MANN MATRIX OPERATION CLASS\n",
    "#from lppc_qcnn.gellmann_ops import ParamOps as param_ops # PARAMETER OPERATIONS HELPER CLASS\n",
    "\n",
    "## qc_data.py\n",
    "# from lppc_qcnn.qc_data import DataLPPC as lppc_data # MNIST DATASET CLASS\n",
    "\n",
    "## qcircuit.py\n",
    "# from lppc_qcnn.qcircuit import QCircuitLPPC as qc_circ # QUANTUM CIRCUIT AND LAYERS CLASS\n",
    "# from lppc_qcnn.qcircuit import OptStepLPPC as opt_lppc # OPTIMIZATION AND COST CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 26pt;\">THE MNIST DATASET</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"qcnn-figures/mnist_plot.png\" alt=\"MNIST Dataset Sample Images\" style=\"display: block; margin-left: auto; margin-right: auto; width: 80%;\">\n",
    "\n",
    "<p style=\"text-align: center; font-family: 'Computer Modern', serif;\">\n",
    "    Sample of the handwritten digital pixelations from the MNIST dataset, which are used for training and testing the QCNN model.<br>\n",
    "    <em>Image source: <a href=\"https://corochann.com/mnist-dataset-introduction-532/\">https://corochann.com/mnist-dataset-introduction-532/</a></em>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt; font-weight: bold;\">Loading the MNIST Dataset:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">For our QCNN, we load the MNIST dataset using TorchVision, which allows us to process the data with quantum features and pass it into our neural network. We define the path for the MNIST data directory below, and use TorchVision to load in the MNIST dataset (Note:  the exact \"path name\" that you choose can be arbitrary and/or at your discretion, as our dataloaders will be able to handle the data loading under most root name cases). We then initialize the batch sizes for the MNIST training and testing data sets. In this model, we set the batch size for the training data at 350, and at 250 for the testing data.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant classclass(es) for MNIST DATA LOADING AND PROCESSING before passing data to QC:\n",
    "from lppc_qcnn.qc_data import DataLPPC as lppc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### READING AND LOADING DATA: \n",
    "\n",
    "# Set directory for data:\n",
    "data_path = './DATA'\n",
    "\n",
    "# Set batch sizes for training and testing data:\n",
    "batch_train_qcnn = 350\n",
    "batch_test_qcnn = 250\n",
    "\n",
    "# Note: Selections of batch_train=350 and batch_test=250 were chosen for our own preferred sample size, and is\n",
    "# also up to your own discretion.\n",
    "train_images, train_labels, test_images, test_labels = lppc_data.load_mnist_torch(batch_train=batch_train_qcnn,\n",
    "                                                                    batch_test=batch_test_qcnn, root=data_path)\n",
    "\n",
    "# Print relevant shapes and types of your training and testing data to check progress:\n",
    "print(f\"train_images shape: {train_images.shape}, dtype: {train_images.dtype}\")\n",
    "print(f\"test_images shape: {test_images.shape}, dtype: {test_images.dtype}\")\n",
    "print(f\"train_labels shape: {train_labels.shape}, dtype: {train_labels.dtype}\")\n",
    "print(f\"test_labels shape: {test_labels.shape}, dtype: {test_labels.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt; font-weight: bold;\">MNIST DATA TRANSFORMATIONS:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">We initialize the reduction sizes for the MNIST training and testing data sets. In this model, we set the reduction size for the training data at 500, and at 100 for the testing data. We then # reduce the number of data points in the training and testing datasets as necessary (Note: it is important to ensure that at least one of the specified reduction values for \"n_train\" and \"n_test\" is smaller than its  corresponding batch size values used during the loading step for the MNIST data, or else no reduction stage is necessary in the steps for the model).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REDUCING THE IMPORTED MNIST DATA\n",
    "\n",
    "# Reduction sizes:\n",
    "n_train_qcnn = 500\n",
    "n_test_qcnn = 100\n",
    "\n",
    "# Reduce datasets as needed:\n",
    "if n_train_qcnn < batch_train_qcnn or n_test_qcnn < batch_test_qcnn:\n",
    "    train_images, train_labels, test_images, test_labels = lppc_data.mnist_reduce(train_images, train_labels,\n",
    "                                        test_images, test_labels, n_train=n_train_qcnn, n_test=n_test_qcnn)\n",
    "\n",
    "# Print relevant shapes and types of your training and testing data to check progress:\n",
    "print(f\"train_images shape: {train_images.shape}, dtype: {train_images.dtype}\")\n",
    "print(f\"test_images shape: {test_images.shape}, dtype: {test_images.dtype}\")\n",
    "print(f\"train_labels shape: {train_labels.shape}, dtype: {train_labels.dtype}\")\n",
    "print(f\"test_labels shape: {test_labels.shape}, dtype: {test_labels.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FLATTENING THE IMPORTED MNIST DATA\n",
    "\n",
    "\n",
    "# TODO\n",
    "train_images, test_images = lppc_data.mnist_flatten(train_images, test_images)\n",
    "\n",
    "# Print relevant shapes and types of your training and testing data to check progress:\n",
    "print(f\"train_images shape: {train_images.shape}, dtype: {train_images.dtype}\")\n",
    "print(f\"test_images shape: {test_images.shape}, dtype: {test_images.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PADDING THE FLATTENED DATASETS\n",
    "\n",
    "\n",
    "# TODO\n",
    "x_train, y_train, x_test, y_test = lppc_data.mnist_padding(train_images, train_labels,\n",
    "                                                           test_images, test_labels)\n",
    "\n",
    "# Print relevant shapes and types of your training and testing data to check progress:\n",
    "print(f\"x_train shape: {x_train.shape}, dtype: {x_train.dtype}\")\n",
    "print(f\"x_test shape: {x_test.shape}, dtype: {x_test.dtype}\")\n",
    "print(f\"y_train shape: {y_train.shape}, dtype: {y_train.dtype}\")\n",
    "print(f\"y_test shape: {y_test.shape}, dtype: {y_test.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">QCNN MODEL</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant classclass(es) for QUANTUM CIRCUIT (before passing weights to the QC):\n",
    "from gellmann_ops import GellMannOps as gell # GELL MANN MATRIX OPERATION CLASS\n",
    "from lppc_qcnn.gellmann_ops import ParamOps as param_ops # PARAMETER OPERATIONS HELPER CLASS\n",
    "\n",
    "from lppc_qcnn.qcircuit import QCircuitLPPC as qc_circ # QUANTUM CIRCUIT AND LAYERS CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Trainable Parameters_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZING QUBIT PARAMETERS\n",
    "\n",
    "# Iniitialize the number of qubits to use within the QCNN. Note that his model is a 10-qubit system.\n",
    "n_qubits = 10  # Number of qubits\n",
    "active_qubits = 10 # Number of active qubits (same as n_qubits, tracks QC operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZING WEIGHTS\n",
    "\n",
    "# TODO\n",
    "qcnn_weights = np.random.uniform(0, np.pi, size=(n_qubits, 1, 3))\n",
    "\n",
    "# TODO\n",
    "qcnn_weights = param_ops.broadcast_params(qcnn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Circuit Construction_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">TRAINING / OPTIMIZATION </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant class(es) for TRAINING AND OPTIMIZATION-RELATED PROCESSES prior to training weights:\n",
    "from lppc_qcnn.qcircuit import OptStepLPPC as opt_lppc # OPTIMIZATION AND COST CLASS\n",
    "# from lppc_qcnn.qcircuit import QCircuitLPPC as qc_circ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Preparation_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Training Model_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPTIMIZATION AND TRAINING\n",
    "\n",
    "\n",
    "# Initialize the selected optimizer (Note: in this model, the Stochastic Gradient Descent (SGD) Optimizer was \n",
    "# determined to be the most suitable, although the choice of optimizer is additionally up to your own discretion.)\n",
    "\n",
    "# Set value to 1, 2, or 3 based on desired optimizer selection from 'opt' (Note: For this model, \"1\" corresponds \n",
    "# to the Stochastic Gradient Descent (SGD) Optimizer. You can use qc_opt_print() to see all available\n",
    "# optimizers to choose from.\n",
    "opt_num_lppc = 1 # TAKE AS PARAMETER\n",
    "\n",
    "# List of all available / acceptable optimizers for QCNN model:\n",
    "# {1: qml.GradientDescentOptimizer,\n",
    "#      2: qml.AdamOptimizer,\n",
    "#      3: qml.COBYLAOptimizer\n",
    "# }\n",
    "\n",
    "# Select Stochastic Gradient Descent (SGD) Optimizer:\n",
    "opt = qc_opt_select(opt_num_lppc)\n",
    "\n",
    "# Initialize important training parameters:\n",
    "learning_rate = 0.1\n",
    "batch_size = 10\n",
    "max_iter = 100\n",
    "conv_tol = 1e-06\n",
    "\n",
    "num_steps = 10\n",
    "loss_history = []\n",
    "\n",
    "# Training Loop:\n",
    "for step in range(num_steps):\n",
    "    qcnn_weights, loss = opt_lppc.stoch_grad_V2(opt, opt_lppc.mse_cost, qcnn_weights, x_train, y_train,\n",
    "                                                learning_rate, batch_size, max_iter, conv_tol)\n",
    "    \n",
    "    loss_history.append(loss)  # Accumulate loss\n",
    "\n",
    "    # Print step and cost:\n",
    "    print(f\"Step {step}: cost = {loss}\")\n",
    "\n",
    "# Evaluate Optimization Accuracy on testing dataset:\n",
    "predictions = np.array([qc_circ.q_circuit_V2(qcnn_weights, xi, active_qubits) for xi in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Accuracy_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREDICTIONS\n",
    "\n",
    "# Calculate and determine accuracy of the QCNN model:\n",
    "accuracy = opt_lppc.accuracy_V1(predictions, y_test)\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 20pt;\">_APPENDIX_</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Computer Modern'; font-size: 10pt; font-weight: bold; text-align: center;\">\n",
    "    © The Laboratory for Particle Physics and Cosmology (LPPC) at Harvard University, Cambridge, MA<br>\n",
    "    © Sean Chisholm<br>\n",
    "    © Pavel Zhelnin\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
