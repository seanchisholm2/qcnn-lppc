{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family: 'Computer Modern'; font-size: 42pt; font-weight: bold;\">Quantum Convolutional Neural Network (QCNN) Using *PennyLane*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS / DEPENDENCIES:\n",
    "\n",
    "# PennyLane:\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches # Quantum Circuit Drawings\n",
    "# mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "# from tqdm import tqdm\n",
    "# import csv\n",
    " \n",
    "# import math\n",
    "# import random\n",
    "\n",
    "from scipy.linalg import expm # Unitary-Related Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 26pt;\">THE MNIST DATASET</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"qcnn-figures/mnist_plot.png\" alt=\"MNIST Dataset Sample Images\" style=\"display: block; margin-left: auto; margin-right: auto; width: 80%;\">\n",
    "\n",
    "<p style=\"text-align: center; font-family: 'Computer Modern', serif;\">\n",
    "    Sample of the handwritten digital pixelations from the MNIST dataset, which are used for training and testing the QCNN model.<br>\n",
    "    <em>Image source: <a href=\"https://corochann.com/mnist-dataset-introduction-532/\">https://corochann.com/mnist-dataset-introduction-532/</a></em>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt; font-weight: bold;\">Loading the MNIST Dataset:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">For our QCNN, we load the MNIST dataset using TorchVision, which allows us to process the data with quantum features and pass it into our neural network. We define the path for the MNIST data directory below, and use TorchVision to load in the MNIST dataset (Note:  the exact \"path name\" that you choose can be arbitrary and/or at your discretion, as our dataloaders will be able to handle the data loading under most root name cases). We then initialize the batch sizes for the MNIST training and testing data sets. In this model, we set the batch size for the training data at 350, and at 250 for the testing data.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant class(es) for MNIST DATA LOADING AND PROCESSING before passing data to QC:\n",
    "from lppc_qcnn.qc_data import DataLPPC as lppc_data # MNIST DATA CLASS\n",
    "from lppc_qcnn.gellmann_ops import GellMannOps as gell_ops # GELL MANN PLUS QUBIT SELECTION OPERATIONS CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_qubits value: 10\n",
      "active_qubits value: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "### QUBIT CONFIGURATION AND SELECTION FOR MNIST DATA:\n",
    "### REQUIRED CLASSES: GellMannOps\n",
    "n_qubits, active_qubits = gell_ops.qubit_select(gell_ops, qubit_config=\"mnist\") # Number of Qubits (10)\n",
    "\n",
    "# Print relevant values:\n",
    "print(f\"n_qubits value: {n_qubits}\")\n",
    "print(f\"active_qubits value: {active_qubits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: torch.Size([350, 1, 28, 28]), dtype: torch.float32\n",
      "test_images shape: torch.Size([250, 1, 28, 28]), dtype: torch.float32\n",
      "train_labels shape: torch.Size([350]), dtype: torch.int64\n",
      "test_labels shape: torch.Size([250]), dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "### READING AND LOADING DATA: \n",
    "### REQUIRED CLASSES: DataLPPC\n",
    "\n",
    "\n",
    "# Set directory for data:\n",
    "data_path = './DATA'\n",
    "\n",
    "# Set batch sizes for training and testing data:\n",
    "batch_train_qcnn = 350\n",
    "batch_test_qcnn = 250\n",
    "\n",
    "# Note: Selections of batch_train=350 and batch_test=250 were chosen for our own preferred sample size, and is\n",
    "# also up to your own discretion.\n",
    "train_images, train_labels, test_images, test_labels = lppc_data.load_mnist_torch(batch_train=batch_train_qcnn,\n",
    "                                                                    batch_test=batch_test_qcnn, root=data_path)\n",
    "\n",
    "# Print relevant shapes and types of your training and testing data to check progress:\n",
    "print(f\"train_images shape: {train_images.shape}, dtype: {train_images.dtype}\")\n",
    "print(f\"test_images shape: {test_images.shape}, dtype: {test_images.dtype}\")\n",
    "print(f\"train_labels shape: {train_labels.shape}, dtype: {train_labels.dtype}\")\n",
    "print(f\"test_labels shape: {test_labels.shape}, dtype: {test_labels.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt; font-weight: bold;\">MNIST DATA TRANSFORMATIONS:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">We initialize the reduction sizes for the MNIST training and testing data sets. In this model, we set the reduction size for the training data at 500, and at 100 for the testing data. We then reduce the number of data points in the training and testing datasets as necessary (Note: it is important to ensure that at least one of the specified reduction values for \"n_train\" and \"n_test\" is smaller than its  corresponding batch size values used during the loading step for the MNIST data, or else no reduction stage is necessary in the steps for the model).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: torch.Size([65, 1, 28, 28]), dtype: torch.float64\n",
      "test_images shape: torch.Size([49, 1, 28, 28]), dtype: torch.float64\n",
      "train_labels shape: torch.Size([65]), dtype: torch.float64\n",
      "test_labels shape: torch.Size([49]), dtype: torch.float64\n"
     ]
    }
   ],
   "source": [
    "### REDUCING THE IMPORTED MNIST DATA\n",
    "### REQUIRED CLASSES: DataLPPC\n",
    "\n",
    "# Reduction sizes:\n",
    "n_train_qcnn = 500\n",
    "n_test_qcnn = 100\n",
    "\n",
    "# Reduce datasets as needed:\n",
    "if n_train_qcnn < batch_train_qcnn or n_test_qcnn < batch_test_qcnn:\n",
    "    train_images, train_labels, test_images, test_labels = lppc_data.mnist_reduce(train_images, train_labels,\n",
    "                                        test_images, test_labels)\n",
    "\n",
    "# Print relevant shapes and types of your training and testing data to check progress:\n",
    "print(f\"train_images shape: {train_images.shape}, dtype: {train_images.dtype}\")\n",
    "print(f\"test_images shape: {test_images.shape}, dtype: {test_images.dtype}\")\n",
    "print(f\"train_labels shape: {train_labels.shape}, dtype: {train_labels.dtype}\")\n",
    "print(f\"test_labels shape: {test_labels.shape}, dtype: {test_labels.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: torch.Size([65, 784]), dtype: torch.float64\n",
      "test_images shape: torch.Size([49, 784]), dtype: torch.float64\n"
     ]
    }
   ],
   "source": [
    "### FLATTENING THE IMPORTED MNIST DATA\n",
    "### REQUIRED CLASSES: DataLPPC\n",
    "\n",
    "train_images, test_images = lppc_data.mnist_flatten(train_images, test_images)\n",
    "\n",
    "# Print relevant shapes and types of your training and testing data to check progress:\n",
    "print(f\"train_images shape: {train_images.shape}, dtype: {train_images.dtype}\")\n",
    "print(f\"test_images shape: {test_images.shape}, dtype: {test_images.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (65, 1024), dtype: float64\n",
      "x_test shape: (49, 1024), dtype: float64\n",
      "y_train shape: (65,), dtype: float64\n",
      "y_test shape: (49,), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### PADDING THE FLATTENED DATASETS\n",
    "### REQUIRED CLASSES: DataLPPC\n",
    "\n",
    "x_train, y_train, x_test, y_test = lppc_data.mnist_padding(train_images, train_labels,\n",
    "                                                           test_images, test_labels)\n",
    "\n",
    "# Print relevant shapes and types of your training and testing data to check progress:\n",
    "print(f\"x_train shape: {x_train.shape}, dtype: {x_train.dtype}\")\n",
    "print(f\"x_test shape: {x_test.shape}, dtype: {x_test.dtype}\")\n",
    "print(f\"y_train shape: {y_train.shape}, dtype: {y_train.dtype}\")\n",
    "print(f\"y_test shape: {y_test.shape}, dtype: {y_test.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">QCNN MODEL</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">*Discuss QCNN model structure and layering here.*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant classclass(es) for QUANTUM CIRCUIT (before passing weights to the QC):\n",
    "from lppc_qcnn.gellmann_ops import ParamOps as param_ops # PARAMETER OPERATIONS HELPER CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Trainable Parameters_:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">We prepare the trainable parameters (weights) for the QCNN by properly transforming their type and shape. We ensure that the weights are Torch tensors of a relevant datatype, and also ensure there are enough weights to train on to be able to pass to the QC, and subsequently through our stochastic gradient descent training loop.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ParamOps' has no attribute 'n_qubits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN-LPPC-Construction_forMNIST.ipynb Cell 23\u001b[0m line \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN-LPPC-Construction_forMNIST.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m qcnn_weights0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\u001b[39m0\u001b[39m, np\u001b[39m.\u001b[39mpi, size\u001b[39m=\u001b[39m(n_qubits,\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN-LPPC-Construction_forMNIST.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Prepare weights and transform them by passing to 'param_prep_lppc':\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN-LPPC-Construction_forMNIST.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m qcnn_weights \u001b[39m=\u001b[39m param_ops\u001b[39m.\u001b[39;49mbroadcast_weights_lppc(param_ops, qcnn_weights0)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN-LPPC-Construction_forMNIST.ipynb#X30sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Print relevant attributes of 'qcnn_weights':\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN-LPPC-Construction_forMNIST.ipynb#X30sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSize of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mqcnn_weights\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mqcnn_weights\u001b[39m.\u001b[39msize\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/VSCode_LPPC/qcnn-lppc/lppc_qcnn/gellmann_ops.py:408\u001b[0m, in \u001b[0;36mParamOps.broadcast_weights_lppc\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39mReturns the most recent version of the BROADCASTING WEIGHTS function \u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[39mused in the QCNN (CURRENT VERSION: V3).\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[39m# Return Current Broadcast Weights ('broadcast_weights_V3') with appropriate arguments:\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbroadcast_weights_V3(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/VSCode_LPPC/qcnn-lppc/lppc_qcnn/gellmann_ops.py:269\u001b[0m, in \u001b[0;36mParamOps.broadcast_weights_V3\u001b[0;34m(self, params, n_qubits)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39m# QUBIT CHECK:\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m#-------------------------------\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m# Check 'n_qubits' is passed:\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[39mif\u001b[39;00m n_qubits \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[39m# FOR RUNNING:\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     n_qubits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_qubits\n\u001b[1;32m    270\u001b[0m     \u001b[39m# n_qubits = 10\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39m#-------------------------------\u001b[39;00m\n\u001b[1;32m    273\u001b[0m params_flat \u001b[39m=\u001b[39m params\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'ParamOps' has no attribute 'n_qubits'"
     ]
    }
   ],
   "source": [
    "### INITIALIZING QUBIT AND WEIGHTS PARAMETERS:\n",
    "### REQUIRED CLASSES: ParamOps, GellMannOps\n",
    "\n",
    "# Initialize Qubits:\n",
    "n_qubits, active_qubits = gell_ops.qubit_select(gell_ops, qubit_config=\"mnist\") # Number of Qubits (10)\n",
    "\n",
    "# Initialize Trainable Parameters (shape of original MNIST data):\n",
    "qcnn_weights0 = np.random.uniform(0, np.pi, size=(n_qubits,1,3))\n",
    "\n",
    "# Prepare weights and transform them by passing to 'param_prep_lppc':\n",
    "qcnn_weights = param_ops.broadcast_weights_lppc(param_ops, qcnn_weights0)\n",
    "\n",
    "# Print relevant attributes of 'qcnn_weights':\n",
    "print(f\"Size of 'qcnn_weights': {qcnn_weights.size}\")\n",
    "print(f\"Shape of 'qcnn_weights': {qcnn_weights.shape}\")\n",
    "print(f\"Length of 'qcnn_weights': {len(qcnn_weights)}\")\n",
    "print(f\"Type of 'qcnn_weights': {type(qcnn_weights)}\")\n",
    "print(f\"Type of an element of 'qcnn_weights': {type(qcnn_weights[0])}\")\n",
    "print(f\"Data type of elements in 'qcnn_weights': {qcnn_weights.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">CIRCUIT DRAWING</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "qubit_select() got multiple values for argument 'qubit_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN-LPPC-Construction_forMNIST.ipynb Cell 25\u001b[0m line \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN-LPPC-Construction_forMNIST.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlppc_qcnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mqcircuit\u001b[39;00m \u001b[39mimport\u001b[39;00m QCircuitLPPC \u001b[39mas\u001b[39;00m qc_circ \u001b[39m# QUANTUM CIRCUIT CLASS\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN-LPPC-Construction_forMNIST.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlppc_qcnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mqcircuit\u001b[39;00m \u001b[39mimport\u001b[39;00m DrawQC \u001b[39mas\u001b[39;00m qc_draw \u001b[39m# QUANTUM CIRCUIT CLASS\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN-LPPC-Construction_forMNIST.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(qc_draw())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN-LPPC-Construction_forMNIST.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m weights1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\u001b[39m0\u001b[39m, np\u001b[39m.\u001b[39mpi, size\u001b[39m=\u001b[39m(n_qubits,\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN-LPPC-Construction_forMNIST.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m qc_draw\u001b[39m.\u001b[39mdraw_pool_layer(qc_draw, weights1, x_test)\n",
      "File \u001b[0;32m~/VSCode_LPPC/qcnn-lppc/lppc_qcnn/qcircuit.py:458\u001b[0m, in \u001b[0;36mDrawQC.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 458\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m()\n\u001b[1;32m    459\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqc_circ \u001b[39m=\u001b[39m QCircuitLPPC() \u001b[39m# Initialize 'QCircuitLPPC' to access circuit functions\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39m# GELLMANNOPS:\u001b[39;00m\n",
      "File \u001b[0;32m~/VSCode_LPPC/qcnn-lppc/lppc_qcnn/qcircuit.py:39\u001b[0m, in \u001b[0;36mQCircuitLPPC.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     38\u001b[0m     \u001b[39m# GELLMANNOPS:\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgell_ops \u001b[39m=\u001b[39m gell_ops() \u001b[39m# Initialize 'GellMannOps' to access variables\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[39m# QUBITS:\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_qubits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgell_ops\u001b[39m.\u001b[39mn_qubits\n",
      "File \u001b[0;32m~/VSCode_LPPC/qcnn-lppc/lppc_qcnn/gellmann_ops.py:33\u001b[0m, in \u001b[0;36mGellMannOps.__init__\u001b[0;34m(self, qubit_test)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, qubit_test\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmnist\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     32\u001b[0m     \u001b[39m# QUBITS (ONLY):\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_qubits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqubit_select(\u001b[39mself\u001b[39;49m, qubit_config\u001b[39m=\u001b[39;49mqubit_test)\n\u001b[1;32m     34\u001b[0m     \u001b[39m# ACTIVE QUBITS (ONLY):\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactive_qubits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqubit_select(\u001b[39mself\u001b[39m, qubit_config\u001b[39m=\u001b[39mqubit_test)\n",
      "\u001b[0;31mTypeError\u001b[0m: qubit_select() got multiple values for argument 'qubit_config'"
     ]
    }
   ],
   "source": [
    "# Import relevant class(es) for CIRCUIT CONSTRUCTION ANF DRAWING prior to visualizations:\n",
    "from lppc_qcnn.qcircuit import QCircuitLPPC as qc_circ # QUANTUM CIRCUIT CLASS\n",
    "from lppc_qcnn.qcircuit import DrawQC as qc_draw # QUANTUM CIRCUIT CLASS\n",
    "\n",
    "print(qc_draw())\n",
    "\n",
    "weights1 = np.random.uniform(0, np.pi, size=(n_qubits,1,3))\n",
    "qc_draw.draw_pool_layer(qc_draw, weights1, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">TRAINING / OPTIMIZATION </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant class(es) for TRAINING AND OPTIMIZATION-RELATED PROCESSES prior to training weights:\n",
    "from lppc_qcnn.qcircuit import OptStepLPPC as opt_lppc # OPTIMIZATION AND COST CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Training Model_:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">We initialize the selected optimizer, and in this model, we determined the Stochastic Gradient Descent (SGD) Optimizer to be the most suitable, although the choice of optimizer used within the QCNN is up to one's personal discretion. We set the value to an integer between 1 and 6 based on the desired optimizer selection from 'opt', which we call 'opt_num'. For this model, '1' corresponds to the Stochastic Gradient Descent (SGD) Optimizer ('opt_num' = 1). We can additionally use qc_opt_print() to see all available optimizers to choose from, if needed.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_num_lppc = 1 # TAKE AS PARAMETER\n",
    "\n",
    "# Select Stochastic Gradient Descent (SGD) Optimizer:\n",
    "# opt = opt_lppc.qcnn_opt_select(opt_num_lppc)\n",
    "opt = qml.GradientDescentOptimizer() # CURRENTLY NOT USING 'qcnn_opt_select'\n",
    "\n",
    "# OPTIMIZER CHECK:\n",
    "#-----------------------------------------\n",
    "# opt_0 = qml.GradientDescentOptimizer()\n",
    "# opt_0.step_and_cost?\n",
    "#-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">We can also list all available optimizer selections for the QCNN. This following optimizer list does not include all of the available optimizer selections in PennyLane; it only includes 6 that we selected based on efficiency and relevance to our model and data. The missing optimizers from PennyLane include: qml.SGDOptimizer, qml.AdagradMaxOptimizer, qml.SparseAdamOptimizer, qml.SPSAOptimizer, qml.QNGOptimizer, and qml.AdaMaxOptimizer.</span>\n",
    "\n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">\n",
    "<br>\n",
    "*Optimizer List*:\n",
    "<br>\n",
    "1: qml.GradientDescentOptimizer (Default/Primary)\n",
    "<br>\n",
    "2: qml.AdamOptimizer\n",
    "<br>\n",
    "3: qml.RMSPropOptimizer\n",
    "<br>\n",
    "4: qml.MomentumOptimizer\n",
    "<br>\n",
    "5: qml.NesterovMomentumOptimizer\n",
    "<br>\n",
    "6: qml.AdagradOptimizer\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPTIMIZATION AND TRAINING\n",
    "### REQUIRED CLASSES: OptStepLPPC, QCircuitLPPC, GellMannOps\n",
    "\n",
    "n_qubits, active_qubits = gell_ops.qubit_select(gell_ops, qubit_config=\"mnist\") # Number of Qubits (10)\n",
    "\n",
    "# Initialize optimization Parameters:\n",
    "learning_rate = 0.1\n",
    "batch_size = 10\n",
    "max_iter = 100\n",
    "conv_tol = 1e-06\n",
    "\n",
    "# Initialize Training History Parameters:\n",
    "num_steps = 10\n",
    "loss_history = []\n",
    "# (Note: uncomment 'hist_lppc' below for access the model's loss history during training)\n",
    "# hist_lppc = True\n",
    "\n",
    "# Training Loop:\n",
    "for step in range(num_steps):\n",
    "    qcnn_weights, loss = opt_lppc.stoch_grad_lppc(opt_lppc, opt, opt_lppc.mse_cost, qcnn_weights, x_train, y_train,\n",
    "                                                  batch_size, max_iter, conv_tol, learning_rate)\n",
    "    \n",
    "    loss_history.append(loss)  # Accumulate loss\n",
    "\n",
    "    # Print step and cost:\n",
    "    print(f\"Step {step}: cost = {loss}\")\n",
    "\n",
    "# Evaluate Optimization Accuracy on testing dataset:\n",
    "predictions = np.array([qc_circ.qcircuit_lppc(qc_circ, qcnn_weights, xi) for xi in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Accuracy_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREDICTIONS AND ACCURACY\n",
    "### REQUIRED CLASSES: OptStepLPPC\n",
    "\n",
    "# Calculate and determine accuracy of the current QCNN model:\n",
    "accuracy = opt_lppc.accuracy_lppc(opt_lppc, predictions, y_test)\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 20pt;\">_APPENDIX_</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Computer Modern'; font-size: 10pt; font-weight: bold; text-align: center;\">\n",
    "    © The Laboratory for Particle Physics and Cosmology (LPPC) at Harvard University, Cambridge, MA<br>\n",
    "    © Sean Chisholm<br>\n",
    "    © Pavel Zhelnin\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
