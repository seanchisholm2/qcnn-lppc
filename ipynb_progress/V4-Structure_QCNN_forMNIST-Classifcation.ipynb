{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 32pt;\">QCNNs for Classification (NEW)</span>\n",
    "#### <span style=\"font-family: 'Computer Modern'; font-size: 18pt;\">Introduction:</span> \n",
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">\n",
    "In this notebook, we walk through the QCNN model and the logic used to generate our final results. This code is then streamlined (removing excess print statements and saving figures of interest) and condensed into the python file `qcnn_classify_phases.py` which was then run using cloud computing resources to accelerate the learning process. \n",
    "\n",
    "This notebook serves as a useful tool for anyone looking to play around with the model and generate some plots quickly. \n",
    "\n",
    "**NOTE:** This version of the notebook has been independently modified to be reliant on the PennyLane framework.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE NOT IN USE BELOW:\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# x_train = np.array([data[0] for data in train_images]) ## data for MNIST training data\n",
    "# y_train = np.array(train_labels) ## labels/classifications for MNIST training data\n",
    "\n",
    "# x_test = np.array([data[0] for data in test_images]) ## data for MNIST testing data\n",
    "# y_test = np.array(test_labels) ## labels/classifications for MNIST testing data\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "#### Shapes and types of each set:\n",
    "#### Shape of train_images: torch.Size([24, 1, 28, 28])\n",
    "#### Shape of train_labels: torch.Size([24])\n",
    "#### Shape of test_images: torch.Size([14, 1, 28, 28])\n",
    "#### Shape of test_labels: torch.Size([14])\n",
    "#### Type of train_images: <class 'torch.Tensor'> ## same as test_images\n",
    "#### Type of train_labels: <class 'torch.Tensor'> ## same as test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QML-Based Imports:\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torch\n",
    "\n",
    "# Data Recognition/Visualization Imports:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "# Data Analysis Imports:\n",
    "import random # for generating random data\n",
    "from sklearn import datasets # for data modeling/constructing\n",
    "from sklearn.model_selection import train_test_split # for data modeling/constructing\n",
    "from sklearn.svm import SVC # for data training\n",
    "\n",
    "# PennyLane Demo-Based Imports (MNIST Data):\n",
    "from pennylane.templates import RandomLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TorchVision:\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QML-Drawing-Based Imports:\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# QML Data-Based Imports:\n",
    "from sklearn.preprocessing import OneHotEncoder # for encoding training and testing data labels\n",
    "\n",
    "# NEW Imports:\n",
    "import copy\n",
    "import sys\n",
    "from scipy.linalg import expm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">FUNCTIONS / CLASSES</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gell Mann Matrix function:\n",
    "\n",
    "def generate_gell_mann(order):\n",
    "    \"\"\"\n",
    "    Generates a list of np.arrays which represent Gell Mann matrices of order 'order'.\n",
    "    eg: order = 2\n",
    "    gm_matrices = [ [[0,  1],\n",
    "                             [1,  0]] ,\n",
    "\n",
    "                            [[0, -i]\n",
    "                             [i,  0]] ,\n",
    "\n",
    "                            [[1,  0],\n",
    "                             [0, -1]] ]\n",
    "    \"\"\"\n",
    "    gm_matrices = []  # Initialize an empty list to store matrices:\n",
    "    for k in range(order):\n",
    "        j = 0\n",
    "        while j < k:\n",
    "            # Generate symmetric and anti-symmetric matrices:\n",
    "            sym = b_mat(j, k, order) + b_mat(k, j, order)  # Create a symmetric matrix:\n",
    "            # Create an anti-symmetric matrix:\n",
    "            anti_sym = complex(0.0, -1.0) * (b_mat(j, k, order) - b_mat(k, j, order))\n",
    "            gm_matrices.append(sym)  # Append symmetric matrix to list:\n",
    "            gm_matrices.append(anti_sym)  # Append anti-symmetric matrix to list:\n",
    "            j += 1\n",
    "\n",
    "        if k < (order - 1):\n",
    "            n = k + 1\n",
    "            coeff = np.sqrt(2 / (n * (n + 1)))  # Calculate coefficient for diagonal matrix:\n",
    "\n",
    "            sum_diag = b_mat(0, 0, order)  # Start with first diagonal element:\n",
    "            for i in range(1, k + 1):\n",
    "                sum_diag += b_mat(i, i, order)  # Sum up to k-th diagonal element:\n",
    "\n",
    "            diag_mat = coeff * (sum_diag - n * (b_mat(k + 1, k + 1, order)))  # Create diagonal matrix:\n",
    "            gm_matrices.append(diag_mat)  # Append diagonal matrix to list:\n",
    "\n",
    "    # Return list of Gell-Mann matrices:\n",
    "    return gm_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Operator function:\n",
    "\n",
    "def get_conv_op(mats, params):\n",
    "    \"\"\"\n",
    "    Parametrizes the convolutional operator according to Gell-Mann matrices scaled by trainable parameters,\n",
    "    this method generates the relevant applicable operator.\n",
    "    \"\"\"\n",
    "    # Initialize a zero matrix with same shape as Gell-Mann matrices:\n",
    "    final = np.zeros(mats[0].shape, dtype=np.complex128)\n",
    "    for mat, param in zip(mats, params):  # Iterate over pairs of matrices and parameters:\n",
    "        final += param * mat  # Accumulate weighted sum of matrices:\n",
    "\n",
    "    # Return matrix exponential of final matrix:\n",
    "    return expm(complex(0, -1) * final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basis Matrix function:\n",
    "\n",
    "def b_mat(i, j, n):\n",
    "    \"\"\"\n",
    "    Generates an n x n matrix of 0s with the i,j th entry is a one.\n",
    "    This is the i,j th basis vector on the space of n x n real matricies\n",
    "\n",
    "    :param i: int, row index (must be < n)\n",
    "    :param j: int, column index (must be < n)\n",
    "    :param n: int, dimension of the matrices\n",
    "    :return: np.array of floats, shape (n,n)\n",
    "    \"\"\"\n",
    "    basis_matrix = np.zeros((n, n), dtype=np.float32)\n",
    "    basis_matrix[i, j] = 1.0\n",
    "\n",
    "    return basis_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">DATA</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Loading / Processing_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This function uses TensorFlow to import the MNIST dataset, and due to environment errors, it is currently\n",
    "# not in use. Intead, we import the MNIST dataset using TorchVision.\n",
    "\n",
    "# Using TensorFLow (Currently Not in Use):\n",
    "def load_mnist_tf():\n",
    "    \"\"\"\n",
    "    Load the MNIST dataset and return training and testing images and labels, using TensorFlow.\n",
    "    \n",
    "    Returns:\n",
    "        train_images (numpy.ndarray): Training images.\n",
    "        train_labels (numpy.ndarray): Training labels.\n",
    "        test_images (numpy.ndarray): Testing images.\n",
    "        test_labels (numpy.ndarray): Testing labels.\n",
    "    \"\"\"\n",
    "    # Load MNIST dataset using TensorFlow:\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_images: torch.Size([1000, 1, 28, 28])\n",
      "Shape of train_labels: torch.Size([1000])\n",
      "Shape of test_images: torch.Size([1000, 1, 28, 28])\n",
      "Type of train_images: <class 'torch.Tensor'>\n",
      "Type of train_labels: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Define normalization transform:\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load train data:\n",
    "# Note: Adjust directory based on your user directory.\n",
    "trainset = datasets.MNIST(root='/Users/seanchisholm/NeutrinosSummer24/QML_Summer-2024/QML-JUNE/DATA', train=True,\n",
    "                          transform=transform, download=True)\n",
    "trainloader = DataLoader(trainset, batch_size=1000, shuffle=True)\n",
    "\n",
    "# Download and load test data:\n",
    "# Note: Adjust directory based on User\n",
    "testset = datasets.MNIST(root='/Users/seanchisholm/NeutrinosSummer24/QML_Summer-2024/QML-JUNE/DATA', train=False,\n",
    "                         transform=transform, download=True)\n",
    "testloader = DataLoader(testset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Extract data from loaders:\n",
    "train_images, train_labels = next(iter(trainloader))\n",
    "test_images, test_labels = next(iter(testloader))\n",
    "\n",
    "# Print relevant shapes and types:\n",
    "print(\"Shape of train_images:\", train_images.shape)\n",
    "print(\"Shape of train_labels:\", train_labels.shape)\n",
    "print(\"Shape of test_images:\", test_images.shape)\n",
    "print(\"Type of train_images:\", type(train_images))\n",
    "print(\"Type of train_labels:\", type(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Reduction_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_images: torch.Size([100, 1, 28, 28])\n",
      "Shape of train_labels: torch.Size([100])\n",
      "Shape of test_images: torch.Size([50, 1, 28, 28])\n",
      "Shape of test_labels: torch.Size([50])\n",
      "Type of train_images: <class 'torch.Tensor'>\n",
      "Type of train_labels: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Multi-Classification -> Binary Classification:\n",
    "#------------------------------------------------------------------------\n",
    "# Select indices for classes 0 and 1 in train_labels:\n",
    "train_idx = np.append(np.where(train_labels.numpy() == 0)[0][:n_train//2],\n",
    "                      np.where(train_labels.numpy() == 1)[0][:n_train//2])\n",
    "\n",
    "# Select indices for classes 0 and 1 in test_labels:\n",
    "test_idx = np.append(np.where(test_labels.numpy() == 0)[0][:n_test//2],\n",
    "                     np.where(test_labels.numpy() == 1)[0][:n_test//2])\n",
    "\n",
    "# Convert indices to PyTorch tensors:\n",
    "train_idx = torch.tensor(train_idx, dtype=torch.long)\n",
    "test_idx = torch.tensor(test_idx, dtype=torch.long)\n",
    "\n",
    "# Filter training and testing data based on 'train_idx' and 'test_idx':\n",
    "train_images = train_images[train_idx]\n",
    "test_images = test_images[test_idx]\n",
    "\n",
    "# Filter labels based on based on 'train_idx' and 'test_idx':\n",
    "train_labels = train_labels[train_idx]\n",
    "test_labels = test_labels[test_idx]\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# Reduce dataset size:\n",
    "n_train = 100\n",
    "n_test = 50\n",
    "train_images = train_images[:n_train]\n",
    "train_labels = train_labels[:n_train]\n",
    "test_images = test_images[:n_test]\n",
    "test_labels = test_labels[:n_test]\n",
    "\n",
    "# Normalize pixel values within [0,1]:\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Print relevant shapes and types V2:\n",
    "print(\"Shape of train_images:\", train_images.shape)\n",
    "print(\"Shape of train_labels:\", train_labels.shape)\n",
    "print(\"Shape of test_images:\", test_images.shape)\n",
    "print(\"Shape of test_labels:\", test_labels.shape)\n",
    "print(\"Type of train_images:\", type(train_images))\n",
    "print(\"Type of train_labels:\", type(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Flattening_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_images: (100, 1024)\n",
      "Shape of train_labels: torch.Size([100])\n",
      "Shape of test_images: (50, 1024)\n",
      "Type of train_images: <class 'pennylane.numpy.tensor.tensor'>\n",
      "Type of train_labels: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Flatten images:\n",
    "train_images = train_images.reshape(train_images.shape[0], -1)\n",
    "test_images = test_images.reshape(test_images.shape[0], -1)\n",
    "# Reshape arrays to add 240 zeroes to each dataset:\n",
    "test_images = np.pad(test_images, ((0, 0), (0, 240)), mode='constant', constant_values=0.0)\n",
    "train_images = np.pad(train_images, ((0, 0), (0, 240)), mode='constant', constant_values=0.0)\n",
    "\n",
    "# Print relevant shapes and types V3:\n",
    "print(\"Shape of train_images:\", train_images.shape)\n",
    "print(\"Shape of train_labels:\", train_labels.shape)\n",
    "print(\"Shape of test_images:\", test_images.shape)\n",
    "print(\"Type of train_images:\", type(train_images))\n",
    "print(\"Type of train_labels:\", type(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">QCNN MODEL</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Layers_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2.75318587 0.15459607 1.40999534]\n",
      "  [2.68850444 0.84130027 1.3562959 ]]\n",
      "\n",
      " [[1.82995065 3.01767526 0.87808793]\n",
      "  [2.03410484 1.35482253 0.93940217]]]\n",
      "(2, 2, 3)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Analyzing Weights Shape/Size/Behavior:\n",
    "\n",
    "n_qubits = 2 # Define number of qubits\n",
    "ex_params = np.random.uniform(0, np.pi, size=(2, n_qubits, 3))\n",
    "print(ex_params)\n",
    "\n",
    "# Parameter Shape:\n",
    "print(ex_params.shape)\n",
    "\n",
    "# Parameter Length:\n",
    "print(len(ex_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer Function:\n",
    "def quantum_conv_layer(weights):\n",
    "    \"\"\"\n",
    "    Applies a quantum convolutional layer.\n",
    "    \"\"\"\n",
    "    n_qubits = 2  # Number of qubits is second dimension of weights\n",
    "    \n",
    "    for i in range(0, n_qubits, 2):\n",
    "        # First rotation on second qubit of pair:\n",
    "        qml.RZ(-np.pi/2, wires=i + 1)\n",
    "        \n",
    "        # First set of rotations on first qubit of pair:\n",
    "        qml.RZ(weights[0][i][0], wires=i)\n",
    "        qml.RY(weights[0][i][1], wires=i + 1)\n",
    "        \n",
    "        # First CNOT gate:\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "        \n",
    "        # Second set of rotations on second qubit of pair:\n",
    "        qml.RY(weights[0][i][2], wires=i + 1)\n",
    "        \n",
    "        # Second CNOT gate:\n",
    "        qml.CNOT(wires=[i + 1, i])\n",
    "        \n",
    "        # Second rotation on first qubit of pair:\n",
    "        qml.RZ(np.pi/2, wires=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling Layer Function:\n",
    "def pennylane_pool_layer():\n",
    "    \"\"\"\n",
    "    Applies two-qubit pooling operation to inputted qubits, including controlled rotation based on \n",
    "    measurement.\n",
    "    \"\"\"\n",
    "    n_qubits = 2  # Determine number of qubits from weights shape:\n",
    "\n",
    "    # Generate Gell-Mann matrices for 2-D space (single qubit operators):\n",
    "    pool_operators = generate_gell_mann(2)  # NEW FUNC\n",
    "    \n",
    "    # Loop over active qubits in pairs # FOR PAIRS OF QUBITS\n",
    "    for i in range(0, n_qubits, 2):  # FOR PAIRS OF QUBITS\n",
    "        q1 = i        # First qubit:\n",
    "        q2 = i + 1    # Second qubit:\n",
    "\n",
    "        # Extract weights for current qubit pair:\n",
    "        new_weights = weights[:, i, :]  # Shape (a, 3):\n",
    "\n",
    "        # Get convolutional operators V1 and V2 from pool operators and weights:\n",
    "        v1 = get_conv_op(pool_operators, new_weights[0])  # Use first set of weights for V1  # NEW FUNC\n",
    "        v2 = get_conv_op(pool_operators, new_weights[1])  # Use second set of weights for V2  # NEW FUNC\n",
    "\n",
    "        # Apply Hadamard gate to first qubit:\n",
    "        qml.Hadamard(wires=q1)\n",
    "        \n",
    "        # Apply first controlled unitary operation:\n",
    "        qml.ControlledQubitUnitary(v1, control_wires=[q1], wires=[q2])\n",
    "        \n",
    "        # Apply Hadamard gate to second qubit:\n",
    "        qml.Hadamard(wires=q2)\n",
    "        \n",
    "        # Apply second controlled unitary operation:\n",
    "        qml.ControlledQubitUnitary(v2, control_wires=[q2], wires=[q1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 15pt;\">_Circuit_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device(s):\n",
    "n_qubits = 2  # Number of qubits\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "# QCNN:\n",
    "@qml.qnode(dev, interface='autograd')\n",
    "def q_conv_circuit(params, x):\n",
    "    \"\"\"\n",
    "    Defines a quantum circuit for training. This circuit encodes the input features using RX gates, applies\n",
    "    two quantum convolutional layers interleaved with a pooling layer, and measures the expectation value of\n",
    "    Pauli-Z on the first qubit.\n",
    "    \"\"\"\n",
    "    # Apply Amtplitude Embedding:\n",
    "    qml.AmplitudeEmbedding(x, wires=range(n_qubits), normalize=True)\n",
    "    \n",
    "    # Apply first convolutional layer function, pass 'params' as argument:\n",
    "    quantum_conv_layer(params)\n",
    "\n",
    "    # Apply pooling layer, pass 'params' as argument:\n",
    "    pennylane_pool_layer(params)\n",
    "    \n",
    "    # Return measure of the PauliZ expectation value:\n",
    "    return [qml.expval(qml.PauliZ(wire)) for wire in range(0, n_qubits, 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">TRAINING</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Weights_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Example Parameter: (2, 3)\n",
      "Shape of 'params': (2, 2, 3)\n",
      "Type of 'params': <class 'pennylane.numpy.tensor.tensor'>\n",
      "Shape of 'params0': (4,)\n",
      "Type of 'params0': <class 'pennylane.numpy.tensor.tensor'>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_params(params, n_qubits=2):\n",
    "    # Flatten images:\n",
    "    params_flat = params.reshape(-1)\n",
    "    \n",
    "    # Desired length for amplitude embedding:\n",
    "    opt_length = 2**n_qubits\n",
    "    \n",
    "    # Pad or truncate to match opt_length:\n",
    "    if len(params_flat) < opt_length:\n",
    "        # Pad with zeros to size of opt_length:\n",
    "        params_flat = np.pad(params_flat, (0, opt_length - len(params_flat)), mode='constant', constant_values=0.0)\n",
    "    else:\n",
    "        # Truncate to opt_length:\n",
    "        params_flat = params_flat[:opt_length]\n",
    "    \n",
    "    return params_flat\n",
    "\n",
    "# Initialize weights:\n",
    "weight_shapes = {\"params\": (2, n_qubits, 3)}\n",
    "qcnn_weights =  np.random.uniform(0, np.pi, size=(2, n_qubits, 3))\n",
    "qcnn_weights_flat = preprocess_params(qcnn_weights, n_qubits=2)\n",
    "\n",
    "# Print relevant shapes and types V5:\n",
    "print(f\"Shape of Example Parameter: {qcnn_weights[0].shape}\")\n",
    "print(\"Shape of 'params':\", qcnn_weights.shape)\n",
    "print(\"Type of 'params':\", type(qcnn_weights))\n",
    "print(\"Shape of 'params0':\", qcnn_weights_flat.shape)\n",
    "print(\"Type of 'params0':\", type(qcnn_weights_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Cost_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error (MSE) function:\n",
    "def mse_cost(params, x, y):\n",
    "    \"\"\"\n",
    "    Computes the Mean Squared Error (MSE) cost function.\n",
    "    \"\"\"\n",
    "    predictions = np.array([q_conv_circuit(params, xi) for xi in x])\n",
    "    return np.mean((predictions - y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Optimization_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Features must be a one-dimensional tensor, or two-dimensional with batching; got shape (2, 2, 3).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [183]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Optimization step:\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[0;32m---> 21\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqcnn_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     23\u001b[0m         loss \u001b[38;5;241m=\u001b[39m cost(params, x_train, y_train)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pennylane/optimize/gradient_descent.py:93\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.step\u001b[0;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, objective_fn, \u001b[38;5;241m*\u001b[39margs, grad_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update trainable arguments with one step of the optimizer.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m        If single arg is provided, list [array] is replaced by array.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     g, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_grad(g, args)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# unwrap from list if one argument, cleaner return\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pennylane/optimize/gradient_descent.py:122\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.compute_grad\u001b[0;34m(objective_fn, args, kwargs, grad_fn)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute gradient of the objective function at the given point and return it along with\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03mthe objective function forward pass (if available).\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    will not be evaluted and instead ``None`` will be returned.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m g \u001b[38;5;241m=\u001b[39m get_gradient(objective_fn) \u001b[38;5;28;01mif\u001b[39;00m grad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m grad_fn\n\u001b[0;32m--> 122\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(g, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    125\u001b[0m num_trainable_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pennylane/_grad.py:165\u001b[0m, in \u001b[0;36mgrad.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n\u001b[0;32m--> 165\u001b[0m grad_value, ans \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m ans\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_value\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/autograd/wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pennylane/_grad.py:183\u001b[0m, in \u001b[0;36mgrad._grad_with_forward\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;129m@unary_to_nary\u001b[39m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_grad_with_forward\u001b[39m(fun, x):\n\u001b[1;32m    180\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function is a replica of ``autograd.grad``, with the only\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m    difference being that it returns both the gradient *and* the forward pass\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    value.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     vjp, ans \u001b[38;5;241m=\u001b[39m \u001b[43m_make_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/autograd/core.py:10\u001b[0m, in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_vjp\u001b[39m(fun, x):\n\u001b[1;32m      9\u001b[0m     start_node \u001b[38;5;241m=\u001b[39m VJPNode\u001b[38;5;241m.\u001b[39mnew_root()\n\u001b[0;32m---> 10\u001b[0m     end_value, end_node \u001b[38;5;241m=\u001b[39m  \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m vspace(x)\u001b[38;5;241m.\u001b[39mzeros()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/autograd/tracer.py:10\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace_stack\u001b[38;5;241m.\u001b[39mnew_trace() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[1;32m      9\u001b[0m     start_box \u001b[38;5;241m=\u001b[39m new_box(x, t, start_node)\n\u001b[0;32m---> 10\u001b[0m     end_box \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_box\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isbox(end_box) \u001b[38;5;129;01mand\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_trace \u001b[38;5;241m==\u001b[39m start_box\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_value, end_box\u001b[38;5;241m.\u001b[39m_node\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/autograd/wrap_util.py:15\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f.<locals>.unary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     subargs \u001b[38;5;241m=\u001b[39m subvals(args, \u001b[38;5;28mzip\u001b[39m(argnum, x))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [183]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Optimization step:\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[0;32m---> 21\u001b[0m     params \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28;01mlambda\u001b[39;00m v: \u001b[43mcost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m, qcnn_weights)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     23\u001b[0m         loss \u001b[38;5;241m=\u001b[39m cost(params, x_train, y_train)\n",
      "Input \u001b[0;32mIn [180]\u001b[0m, in \u001b[0;36mmse_cost\u001b[0;34m(params, x, y)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmse_cost\u001b[39m(params, x, y):\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    Computes the Mean Squared Error (MSE) cost function.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([q_conv_circuit(params, xi) \u001b[38;5;28;01mfor\u001b[39;00m xi \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean((predictions \u001b[38;5;241m-\u001b[39m y) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "Input \u001b[0;32mIn [180]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmse_cost\u001b[39m(params, x, y):\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    Computes the Mean Squared Error (MSE) cost function.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mq_conv_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m xi \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean((predictions \u001b[38;5;241m-\u001b[39m y) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pennylane/qnode.py:976\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshots\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_device_shots(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_device)\n\u001b[1;32m    975\u001b[0m \u001b[38;5;66;03m# construct the tape\u001b[39;00m\n\u001b[0;32m--> 976\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    979\u001b[0m using_custom_cache \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__setitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__delitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    983\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pennylane/qnode.py:862\u001b[0m, in \u001b[0;36mQNode.construct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mget_interface(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mqueuing\u001b[38;5;241m.\u001b[39mAnnotatedQueue() \u001b[38;5;28;01mas\u001b[39;00m q:\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qfunc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape \u001b[38;5;241m=\u001b[39m QuantumScript\u001b[38;5;241m.\u001b[39mfrom_queue(q, shots)\n\u001b[1;32m    866\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [170]\u001b[0m, in \u001b[0;36mq_conv_circuit\u001b[0;34m(params, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mDefines a quantum circuit for training. This circuit encodes the input features using RX gates, applies\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03mtwo quantum convolutional layers interleaved with a pooling layer, and measures the expectation value of\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mPauli-Z on the first qubit.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Apply Amtplitude Embedding:\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAmplitudeEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwires\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_qubits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Apply first convolutional layer function, pass 'params' as argument:\u001b[39;00m\n\u001b[1;32m     17\u001b[0m quantum_conv_layer(params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pennylane/templates/embeddings/amplitude.py:125\u001b[0m, in \u001b[0;36mAmplitudeEmbedding.__init__\u001b[0;34m(self, features, wires, pad_with, normalize, id)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_with \u001b[38;5;241m=\u001b[39m pad_with\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize \u001b[38;5;241m=\u001b[39m normalize\n\u001b[0;32m--> 125\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwires\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_with\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28msuper\u001b[39m(StatePrep, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(features, wires\u001b[38;5;241m=\u001b[39mwires, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pennylane/templates/embeddings/amplitude.py:172\u001b[0m, in \u001b[0;36mAmplitudeEmbedding._preprocess\u001b[0;34m(features, wires, pad_with, normalize)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# check shape\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatures must be a one-dimensional tensor, or two-dimensional with batching; got shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    176\u001b[0m n_features \u001b[38;5;241m=\u001b[39m shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    177\u001b[0m dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(wires)\n",
      "\u001b[0;31mValueError\u001b[0m: Features must be a one-dimensional tensor, or two-dimensional with batching; got shape (2, 2, 3)."
     ]
    }
   ],
   "source": [
    "# ORIGINAL: Currently Not Operative\n",
    "\n",
    "# Training and Testing Data Instantiation:\n",
    "#------------------------------------------------------------------------\n",
    "x_train = np.array([data[0] for data in train_images])\n",
    "x_test = np.array([data[0] for data in test_images])\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# Define relevant cost function (Using MSE for now):\n",
    "cost = mse_cost # sets cost func to mean squared error\n",
    "\n",
    "# Training loop:\n",
    "opt = qml.GradientDescentOptimizer(stepsize=0.4)\n",
    "num_steps = 100\n",
    "\n",
    "# Optimization step:\n",
    "for step in range(num_steps):\n",
    "    params = opt.step(lambda v: cost(v, x_train, y_train), qcnn_weights)\n",
    "    if step % 10 == 0:\n",
    "        loss = cost(params, x_train, y_train)\n",
    "        print(f\"Step {step}: cost = {loss}\")\n",
    "\n",
    "# Evaluate optimization on sample test data:\n",
    "x_test = np.array([data[0] for data in test_states])\n",
    "predictions = np.array([q_conv_circuit(qcnn_weights, xi) for xi in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: Stochastic Gradient Descent (In Progress)\n",
    "\n",
    "# Parameters for optimization:\n",
    "learning_rate = 0.01\n",
    "num_steps = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize parameters:\n",
    "n_qubits = 2  # Number of qubits\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "params = np.random.uniform(0, np.pi, size=(2, n_qubits, 3))\n",
    "# params = params.flatten()\n",
    "\n",
    "def stoch_grad_descent(params, x, y, learning_rate, batch_size):\n",
    "    # Shuffle data:\n",
    "    permutation = np.random.permutation(len(x))\n",
    "    x = x[permutation]\n",
    "    y = y[permutation]\n",
    "\n",
    "    # Process each batch:\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        x_batch = x[i:i + batch_size]\n",
    "        y_batch = y[i:i + batch_size]\n",
    "\n",
    "        # Compute gradient:\n",
    "        grad_cost = qml.grad(mse_cost, argnum=0)\n",
    "        gradients = grad_cost(params, x_batch, y_batch)\n",
    "\n",
    "        # Update parameters:\n",
    "        params = params - learning_rate * gradients\n",
    "\n",
    "    return params\n",
    "\n",
    "step_size = 5\n",
    "\n",
    "# Training loop:\n",
    "for step in range(num_steps):\n",
    "    qcnn_weights = stoch_grad_descent(qcnn_weights, training_data, training_labels, learning_rate, batch_size)\n",
    "    if step % step_size == 0:\n",
    "        loss = mse_cost(qcnn_weights, training_data, training_labels)\n",
    "        print(f\"Step {step}: cost = {loss}\")\n",
    "\n",
    "# Evaluate optimization on sample test data:\n",
    "x_test = np.array([data for data in testing_data])\n",
    "predictions = np.array([q_conv_circuit(params, xi) for xi in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 16pt;\">_Accuracy_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert continuous predictions to class labels (-1 or 1), depending on value distance:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mpredictions\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate accuracy:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_accuracy\u001b[39m(y_true, y_pred):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert continuous predictions to class labels (-1 or 1), depending on value distance:\n",
    "predicted_labels = np.where(predictions >= 0, 1, -1)\n",
    "\n",
    "# Calculate accuracy:\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    total_predictions = len(y_true)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "# Compute accuracy on test dataset:\n",
    "accuracy = calculate_accuracy(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 18pt;\">APPENDIX: _More Circuits, Gates, and Drawings_</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Test Parameter Re-Initialization_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.70843918 2.47357609 1.35955782]\n",
      "  [2.25947246 1.93188041 2.59359611]]\n",
      "\n",
      " [[0.68078307 0.54831338 0.52074872]\n",
      "  [0.65102898 2.2527576  2.72282781]]]\n",
      "(2, 2, 3)\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Analyzing Weights Shape/Size/Behavior:\n",
    "n_qubits = 2 # Define number of qubits\n",
    "\n",
    "# Instantiate parameters:\n",
    "ex_params = np.random.uniform(0, np.pi, size=(2, n_qubits, 3))\n",
    "print(ex_params)\n",
    "\n",
    "# Parameter Shape:\n",
    "print(ex_params.shape)\n",
    "\n",
    "# Parameter Length:\n",
    "print(len(ex_params))\n",
    "\n",
    "# Parameter Size Extraction:\n",
    "w_length = ex_params.shape[-1]\n",
    "print(w_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Gates_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom General Rotation Gate for (variable) size/shape of weights and wires:\n",
    "def G_Rot(weights, wire):\n",
    "    \"\"\"General Rotation Gate to Qubit.\"\"\"\n",
    "    qml.Rot(weights[0], weights[1], weights[2], wires=wire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Circuits_:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With general roations, no 'G_Rot':\n",
    "\n",
    "def two_qubit_pooling(weights):\n",
    "    \n",
    "    # Important parameter values:\n",
    "    n_qubits = 2\n",
    "    n_weights = weights.shape[-1]\n",
    "    \n",
    "    # Apply Rotations/Gates before Measurement:\n",
    "    for i in range(0, n_qubits, 2):\n",
    "        # First set of Rotations (Qubit 1):\n",
    "        qml.Rot(weights[0][i][0], weights[0][i][1], weights[0][i][2], wires=i)\n",
    "        \n",
    "        # First set of Rotations (Qubit 2):\n",
    "        qml.Rot(weights[0][i+1][0], weights[0][i+1][1], weights[0][i+1][2], wires=i+1)\n",
    "    \n",
    "        # First set of CNOT Gates (Qubit 1):\n",
    "        qml.CNOT(wires=[i, i+1])\n",
    "    \n",
    "        # Second set of Rotations (Qubit 1):\n",
    "        qml.Rot(weights[1][i][0], weights[1][i][1], weights[1][i][2], wires=i)\n",
    "    \n",
    "        # Second set of Rotations (Qubit 2):\n",
    "        qml.Rot(weights[1][i+1][0], weights[1][i+1][1], weights[1][i+1][2], wires=i+1)\n",
    "    \n",
    "        # Second set of CNOT Gates (Qubit 2):\n",
    "        qml.CNOT(wires=[i, i+1])\n",
    "    \n",
    "        # Apply controlled rotations (CRot) directly:\n",
    "        qml.CRot(weights[2][i][0], weights[2][i][1], weights[2][i][2], wires=[i, i+1])\n",
    "    \n",
    "    # NOTE: I commented out the PauliZ measure from the pooling function here, but this was strictly to be able to\n",
    "    # use qml.draw below to visualize my results, which requires me to instantiate a circuit uses the layer \n",
    "    # function and returns a measure. When applied to the QCNN as a whole, this needs to be commented back in, or\n",
    "    # else no dimensionality reduction will occur in the QCNN.\n",
    "    \n",
    "    # Perform PauliZ measure to every other Qubit:\n",
    "    #for wire in range(0, n_qubits, 2):\n",
    "    #    qml.expval(qml.PauliZ(wire))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-size: 14pt;\">_Drawings_:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 12pt;\">Drawing #1: _Original Pooling Layer w/ \"Every Other Qubit\" Measure (Not Used Currently)_</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooling Layer Results (2 Qubits) #1:\n",
      "[tensor(0.77182558, requires_grad=True)]\n",
      " -> Pooling Layer with PauliZ Measure @ \"Every Other Qubit\":\n",
      "----------------------------------------------------------------------------------\n",
      "0: Rot(0.39,0.43,0.03)Rot(0.38,0.37,0.74)  <Z>\n",
      "1: Rot(0.86,0.87,0.73)XRot(0.82,0.97,0.04)XRot(0.51,0.08,0.46)     \n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example Usage #1:\n",
    "\n",
    "n_qubits = 2\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n",
    "\n",
    "# Circuit 1: Every Other Qubit\n",
    "#------------------------------------------------------------------------------\n",
    "@qml.qnode(dev)\n",
    "def circuit1(weights):\n",
    "    two_qubit_pooling(weights)\n",
    "    return [qml.expval(qml.PauliZ(wire)) for wire in range(0, n_qubits, 2)]\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "weights = np.random.random((3, n_qubits, 3))  # Example weights\n",
    "print(f'Pooling Layer Results (2 Qubits) #1:')\n",
    "print(circuit1(weights))\n",
    "\n",
    "# Draw Circuit Layer:\n",
    "unit_drawer1 = qml.draw(circuit1)\n",
    "print(f' -> Pooling Layer with PauliZ Measure @ \"Every Other Qubit\":')\n",
    "print(f'-------------------------------------------------------------------------------')\n",
    "print(unit_drawer1(weights))\n",
    "print(f'-------------------------------------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 12pt;\">Drawing #2: _Original Pooling Layer w/ \"Second Qubit in Pair\" Measure (Not Used Currently)_</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooling Layer Results (2 Qubits) #2:\n",
      "[tensor(0.41836457, requires_grad=True)]\n",
      " -> Pooling Layer with PauliZ Measure @ \"Every Other Qubit\":\n",
      "-------------------------------------------------------------------------------\n",
      "0: Rot(0.39,0.43,0.03)Rot(0.38,0.37,0.74)     \n",
      "1: Rot(0.86,0.87,0.73)XRot(0.82,0.97,0.04)XRot(0.51,0.08,0.46)  <Z>\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Circuit 2: Second Qubit of each Pair\n",
    "@qml.qnode(dev)\n",
    "#------------------------------------------------------------------------------\n",
    "def circuit2(weights):\n",
    "    two_qubit_pooling(weights)\n",
    "    return [qml.expval(qml.PauliZ(wire)) for wire in range(1, n_qubits, 2)]\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "print(f'Pooling Layer Results (2 Qubits) #2:')\n",
    "print(circuit2(weights))\n",
    "\n",
    "# Draw Circuit Layer:\n",
    "unit_drawer2 = qml.draw(circuit2)\n",
    "print(f' -> Pooling Layer with PauliZ Measure @ \"Every Other Qubit\":')\n",
    "print(f'-------------------------------------------------------------------------------')\n",
    "print(unit_drawer2(weights))\n",
    "print(f'-------------------------------------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 12pt;\">Drawing #3: _New Convolutional Layer (Updated Original Convolutional Layer)_</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Example Parameter: (3, 2, 3)\n",
      "------------------------\n",
      "Convolutional Layer Circuit (qml.draw):\n",
      "1: RZ(-1.57)RY(0.27)XRY(0.18)  \n",
      "0: RZ(0.89)XRZ(1.57)  \n"
     ]
    }
   ],
   "source": [
    "# Convolutional Layer function for testing and drawing:\n",
    "\n",
    "def quantum_conv_layer_test(weights):\n",
    "    \"\"\"\n",
    "    Applies a quantum convolutional layer.\n",
    "    \"\"\"\n",
    "    n_qubits = weights.shape[1]  # Number of qubits is second dimension of weights\n",
    "    \n",
    "    for i in range(0, n_qubits, 2):\n",
    "        # First rotation on second qubit of pair:\n",
    "        qml.RZ(-np.pi/2, wires=i + 1)\n",
    "        \n",
    "        # First set of rotations on first qubit of pair:\n",
    "        qml.RZ(weights[0][i][0], wires=i)\n",
    "        qml.RY(weights[0][i][1], wires=i + 1)\n",
    "        \n",
    "        # First CNOT gate:\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "        \n",
    "        # Second set of rotations on second qubit of pair:\n",
    "        qml.RY(weights[0][i][2], wires=i + 1)\n",
    "        \n",
    "        # Second CNOT gate:\n",
    "        qml.CNOT(wires=[i + 1, i])\n",
    "        \n",
    "        # Second rotation on first qubit of pair:\n",
    "        qml.RZ(np.pi/2, wires=i)\n",
    "        \n",
    "# Example usage of the function within QNode:\n",
    "#---------------------------------------------------------------------\n",
    "n_qubits = 2\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n",
    "\n",
    "# Convolutional  Layer Test Drawing:\n",
    "#---------------------------------------------------------------------\n",
    "drawer_beta = qml.draw(quantum_conv_layer_test)\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "weights_b = np.random.random((3, n_qubits, 3))  # Example weights\n",
    "\n",
    "print(f\"Shape of Example Parameter: {weights_b.shape}\")\n",
    "print(\"------------------------\")\n",
    "print(r'Convolutional Layer Circuit (qml.draw):')\n",
    "print(drawer_beta(weights_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 12pt;\">Drawing #4: _New Pooling Layer (From GitHub Demo)_</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Example Parameter: (2, 2, 3)\n",
      "------------------------\n",
      "Pooling Layer Circuit (qml.draw):\n",
      "0: HU(M1)  <Z>\n",
      "1: U(M0)H     \n",
      "\n",
      "M0 = \n",
      "[[ 0.41972586-0.34600348j -0.36117318-0.75740724j]\n",
      " [ 0.36117318-0.75740724j  0.41972586+0.34600348j]]\n",
      "M1 = \n",
      "[[ 0.34020092-0.61841904j -0.25994962-0.65897452j]\n",
      " [ 0.25994962-0.65897452j  0.34020092+0.61841904j]]\n"
     ]
    }
   ],
   "source": [
    "# Pooling Layer function for testing and drawing:\n",
    "\n",
    "def pennylane_pool_layer_test(weights):\n",
    "    \"\"\"\n",
    "    Applies two-qubit pooling operation to inputted qubits, including controlled rotation based on \n",
    "    measurement.\n",
    "    \"\"\"\n",
    "    n_qubits = weights.shape[1]  # Determine number of qubits from weights shape:\n",
    "\n",
    "    # Generate Gell-Mann matrices for 2-D space (single qubit operators):\n",
    "    pool_operators = generate_gell_mann(2)  # NEW FUNC\n",
    "    \n",
    "    # Loop over active qubits in pairs # FOR PAIRS OF QUBITS\n",
    "    for i in range(0, n_qubits, 2):  # FOR PAIRS OF QUBITS\n",
    "        q1 = i        # First qubit:\n",
    "        q2 = i + 1    # Second qubit:\n",
    "\n",
    "        # Extract weights for current qubit pair:\n",
    "        new_weights = weights[:, i, :]  # Shape (a, 3):\n",
    "\n",
    "        # Get convolutional operators V1 and V2 from pool operators and weights:\n",
    "        v1 = get_conv_op(pool_operators, new_weights[0])  # Use first set of weights for V1  # NEW FUNC\n",
    "        v2 = get_conv_op(pool_operators, new_weights[1])  # Use second set of weights for V2  # NEW FUNC\n",
    "\n",
    "        # Apply Hadamard gate to first qubit:\n",
    "        qml.Hadamard(wires=q1)\n",
    "        \n",
    "        # Apply first controlled unitary operation:\n",
    "        qml.ControlledQubitUnitary(v1, control_wires=[q1], wires=[q2])\n",
    "        \n",
    "        # Apply Hadamard gate to second qubit:\n",
    "        qml.Hadamard(wires=q2)\n",
    "        \n",
    "        # Apply second controlled unitary operation:\n",
    "        qml.ControlledQubitUnitary(v2, control_wires=[q2], wires=[q1])\n",
    "\n",
    "# Example usage of the function within QNode:\n",
    "#-------------------------------------------------------------------------\n",
    "n_qubits = 2\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def pool_test_circuit(weights):\n",
    "    pennylane_pool_layer_test(weights)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "weights_a = np.random.random((2, n_qubits, 3))  # Example weights\n",
    "\n",
    "# Pooling Layer Test Drawing:\n",
    "#-------------------------------------------------------------------------\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "n_qubits = 2  # Number of qubits for pooling layer circuit drawing\n",
    "drawer_alpha = qml.draw(pool_test_circuit)\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "print(f\"Shape of Example Parameter: {weights_a.shape}\")\n",
    "print(\"------------------------\")\n",
    "print(r'Pooling Layer Circuit (qml.draw):')\n",
    "print(drawer_alpha(weights_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
