{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family: 'Computer Modern'; font-size: 42pt; font-weight: bold;\">Quantum Convolutional Neural Network (QCNN): *Laboratory of Particle Physics and Cosmology (LPPC)*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ***** IMPORTS / DEPENDENCIES *****:\n",
    "\n",
    "### *** PLOTTING ***:\n",
    "import matplotlib; # (NOT ACCESSED)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### *** PENNYLANE ***:\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "### *** DATA ***:\n",
    "import numpy as np\n",
    "# import pandas as pd # (NOT ACCESSED)\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "### *** JAX ***:\n",
    "import jax;\n",
    "## JAX CONFIGURATIONS:\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as jnp\n",
    "# import jax.experimental.sparse as jsp # (NOT ACCESSED)\n",
    "# import jax.scipy.linalg as jsl  # (NOT ACCESSED)\n",
    "\n",
    "### *** RNG ***:\n",
    "seed = 0\n",
    "# Using NumPy (base):\n",
    "# rng = np.random.default_rng(seed=seed) # ORIGINAL (NumPy)\n",
    "# Using JAX (base):\n",
    "rng_jax = jax.random.PRNGKey(seed=seed) # *1* (JAX)\n",
    "rng_jax_arr = jnp.array(rng_jax) # *2* (JAX)\n",
    "\n",
    "### *** OTHER ***:\n",
    "# from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ***** PACKAGE IMPORTS (IN PROGRESS) *****:\n",
    "# ****************************************************************************************\n",
    "## *1* MNIST DATA LOADING CLASS:\n",
    "# from lppc_qcnn.load_qc_data import LoadDataQC # LoadDataQC() <--- STATIC METHOD\n",
    "\n",
    "## *2* QUANTUM CIRCUIT AND LAYERS CLASS:\n",
    "# from lppc_qcnn.circuit_layers import LayersQC # LayersQC() <--- INSTANCE METHOD (SELF)\n",
    "# -> Define Instance of LayersQC:\n",
    "# layers_obj = LayersQC()\n",
    "\n",
    "## *3* TRAIN QCNN / RESULTS CLASS:\n",
    "# from lppc_qcnn.circuit_layers import TrainQC # TrainQC() <--- INSTANCE METHOD (SELF)\n",
    "# -> Define Instance of TrainQC:\n",
    "# layers_obj = TrainQC()\n",
    "\n",
    "## *$* QUANTUM AND MATH OPERATORS CLASS:\n",
    "# from lppc_qcnn.qc_operators import QuantumMathOps # <--- STATIC METHOD\n",
    "# -> Define Instance of QuantumMathOps:\n",
    "# qmo_obj = QuantumMathOps()\n",
    "# ****************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 24pt;\">LOADING MNIST DATASET</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************\n",
    "#           INITIAL PARAMETER SETUP\n",
    "# ********************************************\n",
    "\n",
    "## MNIST DATA LOADING CLASS:\n",
    "from lppc_qcnn.load_qc_data import LoadDataQC # <--- STATIC METHOD\n",
    "\n",
    "## DEFINE VARIABLES:\n",
    "n_qubits = 6 # Number of qubits\n",
    "active_qubits = 6 # Active qubits\n",
    "# active_qubits = list(range(active_qubits))\n",
    "num_wires = 6 # Number of wires\n",
    "num_wires_draw = 2 # Number of wires (DRAWINGS)\n",
    "# num_wires_test = 4 # Number of wires (TEST)\n",
    "\n",
    "## QUANTUM DEVICE:\n",
    "# device = qml.device(\"default.mixed\", wires=num_wires)\n",
    "device = qml.device(\"default.qubit\", wires=num_wires) # Six-qubit device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConcretizationTypeError",
     "evalue": "Abstract tracer value encountered where concrete value is expected: traced array with shape int64[].\nThe size argument of jnp.nonzero must be statically specified to use jnp.nonzero within JAX transformations.\nThe error occurred while tracing the function load_digits_data_jaxV2 at /Users/seanchisholm/VSCode_LPPC/qcnn-lppc/lppc_qcnn/load_qc_data.py:173 for jit. This value became a tracer due to JAX operations on these lines:\n\n  operation a:i64[1797] = device_put[devices=[None] srcs=[None]] b\n    from line /Users/seanchisholm/VSCode_LPPC/qcnn-lppc/lppc_qcnn/load_qc_data.py:200:17 (LoadDataQC.load_digits_data_jaxV2)\n\n  operation a:i64[] = convert_element_type[new_dtype=int64 weak_type=False] b\n    from line /Users/seanchisholm/VSCode_LPPC/qcnn-lppc/lppc_qcnn/load_qc_data.py:203:39 (LoadDataQC.load_digits_data_jaxV2)\n\n  operation a:i64[] = convert_element_type[new_dtype=int64 weak_type=False] b\n    from line /Users/seanchisholm/VSCode_LPPC/qcnn-lppc/lppc_qcnn/load_qc_data.py:203:55 (LoadDataQC.load_digits_data_jaxV2)\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConcretizationTypeError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_package.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_package.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m rng_jax \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mPRNGKey(seed\u001b[39m=\u001b[39mseed)  \u001b[39m# Random Number Generator (JAX)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_package.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# rng_np = np.random.default_rng(seed=seed) # Random Number Generator (NUMPY)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_package.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_package.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m## DIGITS DATA (ORIGINAL):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_package.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# (Note: 'n_train'/'n_test' (N) = VARIABLE, 'num_train'/'num_test' (NUM) = FUNCTION ARGUMENT)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_package.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# x_train, y_train, x_test, y_test = LoadDataQC.load_digits_data(n_train, n_test, rng) # Loading digits\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_package.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m x_train, y_train, x_test, y_test \u001b[39m=\u001b[39m LoadDataQC\u001b[39m.\u001b[39;49mload_digits_data_jaxV2(num_train\u001b[39m=\u001b[39;49mn_train, num_test\u001b[39m=\u001b[39;49mn_test, rng\u001b[39m=\u001b[39;49mrng_jax) \u001b[39m# Loading digits\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_package.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m##         ***** FUNCTIONALITY CHECK PRINT STATEMENTS (DATA) *****\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_package.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# -------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/seanchisholm/VSCode_LPPC/qcnn-lppc/QCNN_package.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m15\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m FUNCTIONALITY CHECK (DATA) \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m15\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m~/VSCode_LPPC/qcnn-lppc/lppc_qcnn/load_qc_data.py:203\u001b[0m, in \u001b[0;36mLoadDataQC.load_digits_data_jaxV2\u001b[0;34m(num_train, num_test, rng)\u001b[0m\n\u001b[1;32m    200\u001b[0m labels \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39masarray(labels)\n\u001b[1;32m    202\u001b[0m \u001b[39m# np -> jax binary classification (ORIGINAL)\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m features \u001b[39m=\u001b[39m features[jnp\u001b[39m.\u001b[39;49mwhere((labels \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m) \u001b[39m|\u001b[39;49m (labels \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m))]\n\u001b[1;32m    204\u001b[0m labels \u001b[39m=\u001b[39m labels[jnp\u001b[39m.\u001b[39mwhere((labels \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m|\u001b[39m (labels \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m))]\n\u001b[1;32m    206\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m# np -> jax binary classification (NEW)\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39mmask = (labels == 0) | (labels == 1)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39mlabels = labels[jax_idx]\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m'''\u001b[39;00m\n",
      "File \u001b[0;32m~/VSCode_LPPC/qcnn-lppc/.conda/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:1946\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(condition, x, y, size, fill_value)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1945\u001b[0m   util\u001b[39m.\u001b[39mcheck_arraylike(\u001b[39m\"\u001b[39m\u001b[39mwhere\u001b[39m\u001b[39m\"\u001b[39m, condition)\n\u001b[0;32m-> 1946\u001b[0m   \u001b[39mreturn\u001b[39;00m nonzero(condition, size\u001b[39m=\u001b[39;49msize, fill_value\u001b[39m=\u001b[39;49mfill_value)\n\u001b[1;32m   1947\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1948\u001b[0m   util\u001b[39m.\u001b[39mcheck_arraylike(\u001b[39m\"\u001b[39m\u001b[39mwhere\u001b[39m\u001b[39m\"\u001b[39m, condition, x, y)\n",
      "File \u001b[0;32m~/VSCode_LPPC/qcnn-lppc/.conda/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:2378\u001b[0m, in \u001b[0;36mnonzero\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2376\u001b[0m mask \u001b[39m=\u001b[39m arr \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m \u001b[39melse\u001b[39;00m (arr \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m   2377\u001b[0m calculated_size \u001b[39m=\u001b[39m mask\u001b[39m.\u001b[39msum() \u001b[39mif\u001b[39;00m size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m size\n\u001b[0;32m-> 2378\u001b[0m calculated_size \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39;49mconcrete_dim_or_error(calculated_size,\n\u001b[1;32m   2379\u001b[0m   \u001b[39m\"\u001b[39;49m\u001b[39mThe size argument of jnp.nonzero must be statically specified \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m   2380\u001b[0m   \u001b[39m\"\u001b[39;49m\u001b[39mto use jnp.nonzero within JAX transformations.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2381\u001b[0m \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m calculated_size \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2382\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(zeros(calculated_size, \u001b[39mint\u001b[39m) \u001b[39mfor\u001b[39;00m dim \u001b[39min\u001b[39;00m arr\u001b[39m.\u001b[39mshape)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/VSCode_LPPC/qcnn-lppc/.conda/lib/python3.11/site-packages/jax/_src/core.py:1534\u001b[0m, in \u001b[0;36mconcrete_or_error\u001b[0;34m(force, val, context)\u001b[0m\n\u001b[1;32m   1532\u001b[0m     \u001b[39mreturn\u001b[39;00m force(val\u001b[39m.\u001b[39maval\u001b[39m.\u001b[39mval)\n\u001b[1;32m   1533\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1534\u001b[0m     \u001b[39mraise\u001b[39;00m ConcretizationTypeError(val, context)\n\u001b[1;32m   1535\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1536\u001b[0m   \u001b[39mreturn\u001b[39;00m force(val)\n",
      "\u001b[0;31mConcretizationTypeError\u001b[0m: Abstract tracer value encountered where concrete value is expected: traced array with shape int64[].\nThe size argument of jnp.nonzero must be statically specified to use jnp.nonzero within JAX transformations.\nThe error occurred while tracing the function load_digits_data_jaxV2 at /Users/seanchisholm/VSCode_LPPC/qcnn-lppc/lppc_qcnn/load_qc_data.py:173 for jit. This value became a tracer due to JAX operations on these lines:\n\n  operation a:i64[1797] = device_put[devices=[None] srcs=[None]] b\n    from line /Users/seanchisholm/VSCode_LPPC/qcnn-lppc/lppc_qcnn/load_qc_data.py:200:17 (LoadDataQC.load_digits_data_jaxV2)\n\n  operation a:i64[] = convert_element_type[new_dtype=int64 weak_type=False] b\n    from line /Users/seanchisholm/VSCode_LPPC/qcnn-lppc/lppc_qcnn/load_qc_data.py:203:39 (LoadDataQC.load_digits_data_jaxV2)\n\n  operation a:i64[] = convert_element_type[new_dtype=int64 weak_type=False] b\n    from line /Users/seanchisholm/VSCode_LPPC/qcnn-lppc/lppc_qcnn/load_qc_data.py:203:55 (LoadDataQC.load_digits_data_jaxV2)\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError"
     ]
    }
   ],
   "source": [
    "# ********************************************\n",
    "#          LOADING THE MNIST DATASET\n",
    "# ********************************************\n",
    "\n",
    "## DEFINE VARIABLES (DATA):\n",
    "num_train = jnp.int64(2) # Binary classification\n",
    "num_test = jnp.int64(2)\n",
    "\n",
    "n_train = jnp.int64(2)\n",
    "n_test = jnp.int64(2)\n",
    "\n",
    "## DATA PARAMETERS:\n",
    "rng_jax = jax.random.PRNGKey(seed=seed)  # Random Number Generator (JAX)\n",
    "# rng_np = np.random.default_rng(seed=seed) # Random Number Generator (NUMPY)\n",
    "\n",
    "## DIGITS DATA (ORIGINAL):\n",
    "# (Note: 'n_train'/'n_test' (N) = VARIABLE, 'num_train'/'num_test' (NUM) = FUNCTION ARGUMENT)\n",
    "# x_train, y_train, x_test, y_test = LoadDataQC.load_digits_data(n_train, n_test, rng) # Loading digits\n",
    "x_train, y_train, x_test, y_test = LoadDataQC.load_digits_data_jaxV2(num_train=n_train, num_test=n_test, rng=rng_jax) # Loading digits\n",
    "\n",
    "\n",
    "##         ***** FUNCTIONALITY CHECK PRINT STATEMENTS (DATA) *****\n",
    "# -------------------------------------------------------------------------\n",
    "print(f\"{'='*15} FUNCTIONALITY CHECK (DATA) {'='*15}\")\n",
    "\n",
    "# Shapes and Types:\n",
    "print(f\"\\n{'='*14} (1) SHAPES AND TYPES {'='*14}\")\n",
    "print(f\"• x_train type:  {type(x_train)}  | shape:  {x_train.shape}\")\n",
    "print(f\"• y_train type:  {type(y_train)}  | shape:  {y_train.shape}\")\n",
    "print(f\"• x_test type:  {type(x_test)}  | shape:  {x_test.shape}\")\n",
    "print(f\"• y_test type:  {type(y_test)}  | shape:  {y_test.shape}\")\n",
    "\n",
    "# Normalization:\n",
    "print(f\"\\n{'='*10} (2) NORMALIZATION {'='*10}\")\n",
    "print(f\"• x_train first row norm:  {np.linalg.norm(x_train[0])}\")\n",
    "print(f\"• x_test first row norm:  {np.linalg.norm(x_test[0])}\")\n",
    "\n",
    "# Label Uniqueness:\n",
    "print(f\"\\n{'='*10} (3) LABEL UNIQUENESS {'='*10}\")\n",
    "print(f\"• Unique labels -> y_train:  {np.unique(y_train)}\")\n",
    "print(f\"• Unique labels -> y_test:  {np.unique(y_test)}\")\n",
    "# -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************\n",
    "#        VISUALIZING THE MNIST DATASET\n",
    "# ********************************************\n",
    "\n",
    "## DRAW MNIST IMAGE:\n",
    "LoadDataQC.draw_mnist_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 24pt;\">CONSTRUCTING QUANTUM CIRCUIT</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************\n",
    "#    VISUALIZING / PLOTTING QUANTUM CIRCUIT\n",
    "# ********************************************\n",
    "\n",
    "## QUANTUM CIRCUIT AND LAYERS CLASS:\n",
    "from lppc_qcnn.circuit_layers import LayersQC # <--- INSTANCE METHOD (SELF)\n",
    "# Define Instance of LayersQC:\n",
    "layers_obj = LayersQC()\n",
    "\n",
    "## DEFINE SAMPLE WEIGHTS / FEATURES:\n",
    "# (Note: Adjust second dimension as needed)\n",
    "weights = np.random.rand(81, 2) # <--- SHAPE ~ [(num_wires // 2) * (3 ** 3)]\n",
    "# weights = jnp.array(weights) # WRAP WITH JAX\n",
    "# weights = np.random.rand(num_wires, 2)\n",
    "last_layer_weights = np.random.rand(4 ** 2 - 1)\n",
    "# last_layer_weights = jnp.array(last_layer_weights) # WRAP WITH JAX\n",
    "# last_layer_weights = np.random.rand(4 ** (num_wires // 2) - 1)\n",
    "features = np.random.rand(2 ** num_wires)\n",
    "# features = jnp.array(features) # WRAP WITH JAX\n",
    "\n",
    "## DRAW QUANTUM CIRCUIT:\n",
    "fig, ax = qml.draw_mpl(layers_obj.conv_net)(\n",
    "layers_obj, weights, last_layer_weights, features\n",
    ")\n",
    "\n",
    "print(\"*** QCNN QUANTUM CIRCUIT ***\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE VARIABLES (CONV DRAWING):\n",
    "n_qubits = 6  # Number of qubits\n",
    "active_qubits = list(range(n_qubits))  # Active qubits\n",
    "num_wires = 6  # Number of wires\n",
    "num_wires_draw = 2  # Number of wires (DRAWINGS)\n",
    "\n",
    "params_conv = weights[:, 0]  # Use appropriate slicing based on your need\n",
    "\n",
    "## CONVOLUTIONAL LAYER:\n",
    "@qml.qnode(device)\n",
    "def conv_circuit(params, active_qubits):\n",
    "    layers_obj.three_conv_layer(params, active_qubits)\n",
    "    return qml.probs(wires=active_qubits[:num_wires_draw])\n",
    "\n",
    "## DRAW CONVOLUTIONAL LAYER CIRCUIT:\n",
    "fig, ax = qml.draw_mpl(conv_circuit)(params_conv, active_qubits)\n",
    "print(\"*** QCNN CONVOLUTIONAL LAYER CIRCUIT ***\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONVOLUTIONAL AND POOLING LAYER:\n",
    "@qml.qnode(device)\n",
    "def conv_and_pooling_circuit(kernel_weights, n_wires):\n",
    "    layers_obj.conv_and_pooling(kernel_weights, n_wires)\n",
    "    return qml.probs(wires=n_wires[:num_wires_draw])\n",
    "\n",
    "## DRAW CONVOLUTIONAL AND POOLING LAYER CIRCUIT:\n",
    "fig, ax = qml.draw_mpl(conv_and_pooling_circuit)(weights[:, 0], active_qubits)\n",
    "print(\"*** QCNN CONVOLUTIONAL AND POOLING LAYER CIRCUIT ***\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************\n",
    "#         TRAINING QCNN / RESULTS (V1)\n",
    "# ********************************************\n",
    "\n",
    "## TRAINING QCNN CLASS:\n",
    "from lppc_qcnn.circuit_layers import TrainQC  # TrainQC() <--- STATIC METHOD (FORMERLY INSTANCE METHOD (SELF))\n",
    "\n",
    "# Define Instance of TrainQC (AS NEEDED):\n",
    "# train_obj = TrainQC\n",
    "# train_obj = TrainQC() # <- INSTANCE METHOD (SELF)\n",
    "\n",
    "## DEFINE TRAIN PARAMETERS:\n",
    "n_test = 2\n",
    "# n_test = jnp.int64(2)\n",
    "n_train = 2\n",
    "# n_train = jnp.int64(2)\n",
    "n_epochs = 100\n",
    "# n_epochs = jnp.int64(100)\n",
    "n_reps = 10\n",
    "# n_reps = jnp.int64(10)\n",
    "\n",
    "## DEFINE TRAIN PARAMETERS (DUMMY):\n",
    "num_test = jnp.int64(2) # for jax dummy variable access (functionality)\n",
    "num_train = jnp.int64(2) # for jax dummy variable access (functionality)\n",
    "num_epochs = jnp.int64(100) # for jax dummy variable access (functionality)\n",
    "\n",
    "# Train QCNN and get results:\n",
    "results_df = TrainQC.compute_aggregated_results(num_train=n_train, num_test=n_test, num_epochs=n_epochs) # *6*\n",
    "\n",
    "## *** ALTERNATES ***:\n",
    "#results_df = train_obj.compute_aggregated_results(train_obj, n_train, n_test)  # *1*\n",
    "#results_df = train_obj.compute_aggregated_results(n_train, n_test)  # *2*\n",
    "#results_df = train_obj.compute_aggregated_results(n_train=n_train, n_test=n_test) # *3*\n",
    "#results_df = compute_results(n_train=n_train, n_test=n_test, n_epochs=n_epochs) *4*\n",
    "#results_df = compute_results_jit(n_train=n_train, n_test=n_test, n_epochs=n_epochs) # *5*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************\n",
    "#     PLOTTING AGGREGATED TRAINING RESULTS\n",
    "# ********************************************\n",
    "\n",
    "## DEFINE TRAIN PARAMETERS (ALSO ABOVE):\n",
    "# n_test = 2\n",
    "n_train = 2\n",
    "n_epochs = 100\n",
    "steps = 100\n",
    "# train_obj = TrainQC() (RECALL)\n",
    "\n",
    "# Plot aggregated training results:\n",
    "TrainQC.plot_aggregated_results(results_df, n_train, steps=n_epochs, \n",
    "                                  title_loss='Train and Test Losses', \n",
    "                                  title_accuracy='Train and Test Accuracies', \n",
    "                                  markevery=10) # *1*\n",
    "\n",
    "## ALTERNATES:\n",
    "'''\n",
    "TrainQC.plot_aggregated_results(results_df, n_train, steps, \n",
    "                                  title_loss='Train and Test Losses', \n",
    "                                  title_accuracy='Train and Test Accuracies', \n",
    "                                  markevery=10) # *2* (NO SELF)\n",
    "TrainQC.plot_aggregated_results(results_df, n_train=n_train, steps=steps, \n",
    "                                  title_loss='Train and Test Losses', \n",
    "                                  title_accuracy='Train and Test Accuracies', \n",
    "                                  markevery=10) # *3*\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Computer Modern'; font-weight: bold; font-size: 24pt;\">CODE TESTING / VALIDATION</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ***** DATA (FOR FUTURE IMPLEMENTATION) *****:\n",
    "# x_train, y_train, x_test, y_test = load_moments(n_train, n_test, rng) # Loading moments\n",
    "# x_train, y_train, x_test, y_test = load_IC_data(n_train, n_test, rng) # Loading IC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ***** TESTING RNG TYPES *****:\n",
    "\n",
    "# Example usage of numpy.random.Generator\n",
    "rng = np.random.default_rng()\n",
    "print(f\"Type of rng: {type(rng)}\")\n",
    "\n",
    "# Example usage of jax.random.PRNGKey\n",
    "rng_jax = jax.random.PRNGKey(0)\n",
    "print(f\"Type of rng_jax: {type(rng_jax)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ***** RANDOM *****:\n",
    "\n",
    "'''\n",
    "a = x_train[0]\n",
    "\n",
    "# ************************************************\n",
    "\n",
    "print(type(a))\n",
    "\n",
    "# ************************************************\n",
    "\n",
    "full_array = jnp.array(\n",
    "        [\n",
    "            [\n",
    "                [0,0,0],\n",
    "                [2,2,2],\n",
    "                [0,0,0],\n",
    "                [0,0,0]\n",
    "            ],\n",
    "            [\n",
    "                [1,1,1],\n",
    "                [0,0,0],\n",
    "                [0,0,0],\n",
    "                [0,0,0]\n",
    "            ],\n",
    "            [\n",
    "                [1,1,1],\n",
    "                [0,0,0],\n",
    "                [0,0,0],\n",
    "                [0,0,0]\n",
    "            ]\n",
    "        ]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ***** TESTING JIT-COMPILED DATA LOADING *****:\n",
    "\n",
    "'''\n",
    "## JAX DIGITS DATA:\n",
    "# Load data outside JIT-compiled function (AS NEEDED):\n",
    "x_train, y_train, x_test, y_test = LoadDataQC.load_digits_data(n_train, n_test, rng)\n",
    "'''\n",
    "\n",
    "'''\n",
    "### ***** ATTEMPT 1 (Wrapping 'compute_aggregated_results') *****:\n",
    "# Define wrapper function to call method and apply jax:\n",
    "compute_results = jax.jit(train_obj.compute_aggregated_results)\n",
    "\n",
    "# Run training for multiple sizes and aggregate results:\n",
    "results_df = compute_results(n_train=n_train, n_test=n_test, n_epochs=n_epochs) # *4 (WRAPPED WITH JAX) *\n",
    "\n",
    "### ***** ATTEMPT 2 (Wrapping 'compute_aggregated_results') *****:\n",
    "# Wrapper Function for 'compute_aggregated_results':\n",
    "def compute_results(train_obj, n_train, n_test, n_epochs):\n",
    "    return train_obj.compute_aggregated_results(n_train=n_train, n_test=n_test, n_epochs=n_epochs)\n",
    "    # return train_obj.compute_aggregated_results(train_obj, n_train=n_train, n_test=n_test, n_epochs=n_epochs)\n",
    "# compute_results = jax.jit(train_obj.compute_aggregated_results)\n",
    "\n",
    "### ***** ATTEMPT 3 (Wrapping 'compute_aggregated_results') *****:\n",
    "train_obj = TrainQC()\n",
    "# New results function for wrapping:\n",
    "def compute_results_wrapper(n_train, n_test, n_epochs):\n",
    "    return train_obj.compute_aggregated_results(n_train, n_test, n_epochs)\n",
    "\n",
    "# JIT-compile Wrapper Function:\n",
    "compute_results_jit = jax.jit(compute_results_wrapper)\n",
    "#compute_jit = jax.jit(lambda n_train, n_test, n_epochs: compute_results_wrapper(train_obj, n_train, n_test, n_epochs))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************\n",
    "#         TRAINING QCNN / RESULTS (V2)\n",
    "# ********************************************\n",
    "\n",
    "'''\n",
    "### ***** TRAINING QCNN W/O LOOP FUNCTION ('train_qcnn) *****:\n",
    "from lppc_qcnn.circuit_layers import TrainQC  # TrainQC() <--- INSTANCE METHOD (SELF)\n",
    "\n",
    "# Define Instance of TrainQC:\n",
    "# train_obj = TrainQC\n",
    "train_obj = TrainQC()\n",
    "\n",
    "## DEFINE TRAIN PARAMETERS:\n",
    "n_test = 2\n",
    "n_train = 2\n",
    "n_epochs = 100\n",
    "n_reps = 10\n",
    "\n",
    "# Define wrapper function to call method and apply jax:\n",
    "@jax.jit\n",
    "def run_iterations(n_train, n_test):\n",
    "    return train_obj.run_iterations(n_train=n_train, n_test=n_test)\n",
    "\n",
    "## RUN TRAINING LOOP:\n",
    "train_sizes = [2]\n",
    "results_df = run_iterations(n_train=n_train, n_test=n_test)\n",
    "for n_train in train_sizes[1:]:\n",
    "    results_df = pd.concat([results_df, run_iterations(n_train=n_train, n_test=n_test)])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ***** FUNCTIONALITY CHECK FOR TRAINING DICTIONARY (TrainQC.train_qcnn(args, *kwargs)) *****:\n",
    "\n",
    "'''\n",
    "train_dict = dict(\n",
    "    n_train=[n_train] * n_epochs,\n",
    "    step=jnp.arange(1, n_epochs + 1, dtype=int), # NP -> JNP\n",
    "    train_cost=train_cost_epochs,\n",
    "    train_acc=train_acc_epochs,\n",
    "    test_cost=test_cost_epochs,\n",
    "    test_acc=test_acc_epochs,\n",
    ")\n",
    "# TYPE (DICTIONARY):\n",
    "print(f\"train_dict: type = {type(train_dict)}\")\n",
    "\n",
    "# SHAPES AND TYPES (DICTIONARY ITEMS):\n",
    "print(f\"train_dict shapes and types:\")\n",
    "for key, value in train_dict.items():\n",
    "    print(f\"{key}: shape = {jnp.shape(value)}, type = {type(value)}\") # NP -> JNP\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
